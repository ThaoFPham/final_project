import streamlit as st
import pandas as pd
import numpy as np
import plotly.express as px
import plotly.graph_objects as go
import re
import string
import os
import json
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.decomposition import PCA
from sklearn.cluster import KMeans
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.naive_bayes import GaussianNB
from sklearn.svm import SVC
from sklearn.tree import DecisionTreeClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import accuracy_score, classification_report, silhouette_score
from sklearn.model_selection import train_test_split
from sklearn.metrics.pairwise import cosine_similarity
import pickle
from gensim import corpora, models, similarities

try:
    from pyspark.sql import SparkSession
    from pyspark.sql.types import StructType, StructField, IntegerType, StringType, DoubleType
    from pyspark.ml.feature import VectorAssembler, StringIndexer
    from pyspark.ml.classification import LogisticRegression as SparkLogisticRegression, DecisionTreeClassifier as SparkDecisionTreeClassifier
    from pyspark.ml.evaluation import MulticlassClassificationEvaluator
    from pyspark.ml import Pipeline
    PYSPARK_AVAILABLE = True
except ImportError:
    PYSPARK_AVAILABLE = False

# C·∫•u h√¨nh trang
st.set_page_config(
    page_title="AI Company Recommendation System AT IT_Viec",
    page_icon="ü§ñ",
    layout="wide",
    initial_sidebar_state="expanded"
)

# CSS t√πy ch·ªânh
st.markdown("""
<style>
    .main-header {
        font-size: 2.5rem;
        font-weight: bold;
        color: #1f77b4;
        text-align: center;
        margin-bottom: 2rem;
    }
    .section-header {
        font-size: 1.8rem;
        font-weight: bold;
        color: #2c3e50;
        margin-bottom: 1rem;
    }
    .company-card {
        background-color: #f8f9fa;
        padding: 1rem;
        border-radius: 10px;
        border-left: 4px solid #1f77b4;
        margin-bottom: 1rem;
    }
    .cluster-card {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        padding: 1.5rem;
        border-radius: 15px;
        color: white;
        margin-bottom: 1rem;
    }
    .sentiment-positive {
        background-color: #d4edda;
        border-left: 4px solid #28a745;
        padding: 1rem;
        border-radius: 8px;
        margin-bottom: 1rem;stream
    }
    .sentiment-negative {
        background-color: #f8d7da;
        border-left: 4px solid #dc3545;
        padding: 1rem;
        border-radius: 8px;
        margin-bottom: 1rem;
    }
    .sentiment-neutral {
        background-color: #fff3cd;
        border-left: 4px solid #ffc107;
        padding: 1rem;
        border-radius: 8px;
        margin-bottom: 1rem;
    }
    .prediction-container {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        padding: 2rem;
        border-radius: 15px;
        color: white;
        margin-bottom: 2rem;
    }
    .success-box {
        background-color: #d4edda;
        border: 1px solid #c3e6cb;
        color: #155724;
        padding: 1rem;
        border-radius: 5px;
        margin: 1rem 0;
    }
    .warning-box {
        background-color: #fff3cd;
        border: 1px solid #ffeaa7;
        color: #856404;
        padding: 1rem;
        border-radius: 5px;
        margin: 1rem 0;
    }
    .error-box {
        background-color: #f8d7da;
        border: 1px solid #f5c6cb;
        color: #721c24;
        padding: 1rem;
        border-radius: 5px;
        margin: 1rem 0;
    }
</style>
""", unsafe_allow_html=True)

# Kh·ªüi t·∫°o session state
if 'data_loaded' not in st.session_state:
    st.session_state.data_loaded = False
if 'model_trained' not in st.session_state:
    st.session_state.model_trained = False

# Class x·ª≠ l√Ω vƒÉn b·∫£n t√≠ch h·ª£p t·ª´ code c·ªßa b·∫°n
class TextProcessor:
    def __init__(self):
        self.teen_dict = {}
        self.stopwords_lst = []
        self.wrong_lst = []
        self.load_dictionaries()
    
    def load_dictionaries(self):
        """Load c√°c t·ª´ ƒëi·ªÉn x·ª≠ l√Ω vƒÉn b·∫£n t·ª´ files ho·∫∑c fallback"""
        try:
            # Load teencode t·ª´ file ho·∫∑c fallback
            teencode_paths = ['files/teencode.txt', 'teencode.txt']
            for path in teencode_paths:
                if os.path.exists(path):
                    with open(path, 'r', encoding="utf8") as file:
                        teen_lst = file.read().split('\n')
                        for line in teen_lst:
                            if '\t' in line:
                                key, value = line.split('\t', 1)
                                self.teen_dict[key] = str(value)
                    break
            else:
                # Fallback teencode dictionary
                self.teen_dict = {
                    'ko': 'kh√¥ng', 'k': 'kh√¥ng', 'dc': 'ƒë∆∞·ª£c', 'vs': 'v·ªõi',
                    'tks': 'thanks', 'ty': 'thank you', 'ok': 'okay', 'oke': 'okay',
                    'bt': 'b√¨nh th∆∞·ªùng', 'nc': 'n√≥i chuy·ªán', 'kb': 'k·∫øt b·∫°n'
                }
            
            # Load stopwords t·ª´ file ho·∫∑c fallback
            stopwords_paths = ['files/vietnamese-stopwords_rev.txt', 'vietnamese-stopwords_rev.txt']
            for path in stopwords_paths:
                if os.path.exists(path):
                    with open(path, 'r', encoding="utf8") as file:
                        self.stopwords_lst = file.read().split('\n')
                    break
            else:
                # Fallback stopwords
                self.stopwords_lst = [
                    'v√†', 'c·ªßa', 'c√≥', 'l√†', 'ƒë∆∞·ª£c', 'trong', 'v·ªõi', 'ƒë·ªÉ', 'cho', 't·ª´',
                    'm·ªôt', 'c√°c', 'n√†y', 'ƒë√≥', 'nh·ªØng', 'nhi·ªÅu', 'r·∫•t', 'c≈©ng', 's·∫Ω',
                    'ƒë√£', 'ƒëang', 'v·ªÅ', 'theo', 'nh∆∞', 'khi', 'n·∫øu', 'v√¨', 'do', 'b·ªüi'
                ]
            
            # Load wrong words t·ª´ file ho·∫∑c fallback
            wrong_words_paths = ['files/wrong-word_rev.txt', 'wrong-word_rev.txt']
            for path in wrong_words_paths:
                if os.path.exists(path):
                    with open(path, 'r', encoding="utf8") as file:
                        self.wrong_lst = file.read().split('\n')
                    break
            else:
                self.wrong_lst = ['zzz', 'xxx', 'aaa', 'bbb', 'ccc']
                    
        except Exception as e:
            st.warning(f"‚ö†Ô∏è Kh√¥ng th·ªÉ load m·ªôt s·ªë file t·ª´ ƒëi·ªÉn: {e}")
    
    def clean_text(self, text):
        """L√†m s·∫°ch vƒÉn b·∫£n c∆° b·∫£n - t√≠ch h·ª£p t·ª´ code c·ªßa b·∫°n"""
        if not text or pd.isna(text):
            return ""
        text = str(text).lower()  # Hoa -> th∆∞·ªùng
        text = re.sub(rf"[{string.punctuation}]", "", text)  # B·ªè d·∫•u c√¢u
        text = re.sub(r"\b(g|ml)\b", "", text)  # B·ªè t·ª´ 'g' ho·∫∑c 'ml' khi n√≥ l√† c·∫£ t·ª´
        text = re.sub(r"\s+", " ", text).strip()  # X√≥a kho·∫£ng tr·∫Øng th·ª´a
        text = re.sub(r"^[\-\+\*\‚Ä¢\‚óè\¬∑\~\‚Äì\‚Äî\>]+", "", text)  # B·ªè d·∫•u ƒë·∫ßu c√¢u
        return text
    
    def fix_teencode(self, text):
        """S·ª≠a teencode - t√≠ch h·ª£p t·ª´ code c·ªßa b·∫°n"""
        words = text.split()
        corrected = [self.teen_dict.get(word, word) for word in words]
        return " ".join(corrected)
    
    def remove_wrongword(self, text):
        """Lo·∫°i b·ªè t·ª´ sai"""
        words = text.split()
        trueword = [word for word in words if word not in self.wrong_lst]
        return " ".join(trueword)
    
    def remove_stopword(self, text):
        """Lo·∫°i b·ªè stopwords - t√≠ch h·ª£p t·ª´ code c·ªßa b·∫°n"""
        words = text.split()
        stopword = [word for word in words if word not in self.stopwords_lst]
        return " ".join(stopword)
    
    def clean_pipeline(self, text):
        """Pipeline x·ª≠ l√Ω vƒÉn b·∫£n ho√†n ch·ªânh - t√≠ch h·ª£p t·ª´ code c·ªßa b·∫°n"""
        if not text or pd.isna(text):
            return ""
        text = self.clean_text(text)
        text = self.fix_teencode(text)
        text = self.remove_wrongword(text)
        text = self.remove_stopword(text)
        return text

# Class h·ªá th·ªëng ML v·ªõi d·ªØ li·ªáu th·ª±c
class CompanyRecommendationSystem:
    def __init__(self):
        self.clustercty = None
        self.tfidf = TfidfVectorizer(max_features=500)
        self.pca = PCA(n_components=50, random_state=42)
        self.best_model = None
        self.df_structured_encoded = None
        self.X_full = None
        self.text_processor = TextProcessor()
        self.structured_cols = ['Company Type', 'Company industry', 'Company size', 'Country', 'Working days', 'Overtime Policy']
        self.text_cols = ['Company overview_new', "Why you'll love working here_new", 'Our key skills_new', 'keyword']
        
    @st.cache_data
    def load_data(_self):
        """Load v√† x·ª≠ l√Ω d·ªØ li·ªáu th·ª±c - KH√îNG t·∫°o sample data"""
        try:
            # ƒê∆∞·ªùng d·∫´n file d·ªØ li·ªáu th·ª±c
            data_paths = {
                'translated_data': 'data/translated_data.csv',
                'top2_clusters': 'data/top2_clusters_per_company.csv', 
                'sentiment_data': 'data/sentiment_by_company.csv'
            }
            
            # Ki·ªÉm tra file t·ªìn t·∫°i
            missing_files = []
            for name, path in data_paths.items():
                if not os.path.exists(path):
                    missing_files.append(path)
            
            if missing_files:
                st.markdown(f"""
                <div class="error-box">
                    <h4>‚ùå Kh√¥ng t√¨m th·∫•y c√°c file d·ªØ li·ªáu c·∫ßn thi·∫øt:</h4>
                    <ul>
                        {''.join([f'<li>{file}</li>' for file in missing_files])}
                    </ul>
                    <p><strong>H∆∞·ªõng d·∫´n:</strong></p>
                    <ol>
                        <li>T·∫°o th∆∞ m·ª•c <code>data/</code> trong project</li>
                        <li>Upload c√°c file CSV v√†o th∆∞ m·ª•c <code>data/</code></li>
                        <li>ƒê·∫£m b·∫£o t√™n file ch√≠nh x√°c nh∆∞ tr√™n</li>
                        <li>Refresh l·∫°i trang</li>
                    </ol>
                </div>
                """, unsafe_allow_html=True)
                return False
            
            # Load d·ªØ li·ªáu th·ª±c
            st.info("üìÇ ƒêang load d·ªØ li·ªáu th·ª±c t·ª´ files...")
            
            with st.spinner("Loading translated_data.csv..."):
                clustercty = pd.read_csv(data_paths['translated_data'])
                st.success(f"‚úÖ Loaded {len(clustercty)} companies from translated_data.csv")
            
            with st.spinner("Loading cluster data..."):
                new_data = pd.read_csv(data_paths['top2_clusters'])
                st.success(f"‚úÖ Loaded {len(new_data)} cluster records")
            
            with st.spinner("Loading sentiment data..."):
                sentiment_cln = pd.read_csv(data_paths['sentiment_data'])
                st.success(f"‚úÖ Loaded {len(sentiment_cln)} sentiment records")
            
            # Ki·ªÉm tra d·ªØ li·ªáu kh√¥ng tr·ªëng
            if clustercty.empty or new_data.empty or sentiment_cln.empty:
                st.error("‚ùå M·ªôt ho·∫∑c nhi·ªÅu file CSV tr·ªëng! Vui l√≤ng ki·ªÉm tra d·ªØ li·ªáu.")
                return False
            
            # Merge d·ªØ li·ªáu theo logic c·ªßa b·∫°n
            st.info("üîó ƒêang merge d·ªØ li·ªáu...")
            new_data = pd.merge(new_data, sentiment_cln[['Company Name','sentiment_group']], on='Company Name', how='left')
            clustercty = clustercty.merge(new_data[['Company Name', 'keyword', 'sentiment_group']], on='Company Name', how='left')
            
            # X·ª≠ l√Ω c·ªôt kh√¥ng c·∫ßn thi·∫øt
            if 'Unnamed: 0' in clustercty.columns:
                clustercty.drop(columns=['Unnamed: 0'], inplace=True)
            
            # ƒêi·ªÅn gi√° tr·ªã null
            clustercty['keyword'].fillna('kh√¥ng x√°c ƒë·ªãnh', inplace=True)
            clustercty['sentiment_group'].fillna('neutral', inplace=True)
            
            # Ki·ªÉm tra c√°c c·ªôt c·∫ßn thi·∫øt
            required_cols = _self.structured_cols + _self.text_cols
            missing_cols = [col for col in required_cols if col not in clustercty.columns]
            
            if missing_cols:
                st.error(f"‚ùå Thi·∫øu c√°c c·ªôt c·∫ßn thi·∫øt: {missing_cols}")
                st.info("üìã C√°c c·ªôt c√≥ s·∫µn: " + ", ".join(clustercty.columns.tolist()))
                return False
            
            # L∆∞u d·ªØ li·ªáu
            _self.clustercty = clustercty
            st.success(f"üéâ Load d·ªØ li·ªáu th√†nh c√¥ng: {len(clustercty)} c√¥ng ty v·ªõi ƒë·∫ßy ƒë·ªß th√¥ng tin!")
            
            # Hi·ªÉn th·ªã th·ªëng k√™
            col1, col2, col3, col4 = st.columns(4)
            with col1:
                st.metric("üìä T·ªïng c√¥ng ty", len(clustercty))
            with col2:
                st.metric("üè≠ S·ªë ng√†nh", clustercty['Company industry'].nunique())
            with col3:
                st.metric("üòä C√≥ sentiment", clustercty['sentiment_group'].notna().sum())
            with col4:
                st.metric("üîë C√≥ keywords", clustercty['keyword'].notna().sum())
            
            return True
            
        except Exception as e:
            st.markdown(f"""
            <div class="error-box">
                <h4>‚ùå L·ªói load d·ªØ li·ªáu:</h4>
                <p><strong>Chi ti·∫øt l·ªói:</strong> {str(e)}</p>
                <p><strong>H∆∞·ªõng d·∫´n kh·∫Øc ph·ª•c:</strong></p>
                <ol>
                    <li>Ki·ªÉm tra format file CSV (UTF-8 encoding)</li>
                    <li>ƒê·∫£m b·∫£o c√°c c·ªôt c·∫ßn thi·∫øt c√≥ trong file</li>
                    <li>Ki·ªÉm tra ƒë∆∞·ªùng d·∫´n file</li>
                    <li>Th·ª≠ load t·ª´ng file ri√™ng l·∫ª ƒë·ªÉ debug</li>
                </ol>
            </div>
            """, unsafe_allow_html=True)
            return False
    
    
    def recommend_companies(self, user_input, text_input, threshold=0.1):
        """ƒê·ªÅ xu·∫•t c√¥ng ty"""
        try:
            # X·ª≠ l√Ω text input
            cleaned_text = self.text_processor.clean_pipeline(text_input)
            tfidf_vec = self.tfidf.transform([cleaned_text])
            
            # X·ª≠ l√Ω structured input
            structured_df = pd.DataFrame([user_input])
            structured_encoded = pd.get_dummies(structured_df)
            
            # ƒê·∫£m b·∫£o c√≥ ƒë·ªß columns
            missing_cols = set(self.df_structured_encoded.columns) - set(structured_encoded.columns)
            for col in missing_cols:
                structured_encoded[col] = 0
            structured_encoded = structured_encoded[self.df_structured_encoded.columns]
            
            # G·ªôp features
            user_input_vector = pd.concat([
                structured_encoded.reset_index(drop=True), 
                pd.DataFrame(tfidf_vec.toarray(), columns=self.tfidf.get_feature_names_out())
            ], axis=1)
            
            # PCA transform
            user_input_pca = self.pca.transform(user_input_vector)
            
            # Predict cluster
            predicted_cluster = self.best_model.predict(user_input_pca)[0]
            
            # T√≠nh Cosine Similarity
            company_text_vectors = self.tfidf.transform(self.clustercty['combined_text'])
            similarity_scores = cosine_similarity(tfidf_vec, company_text_vectors).flatten()
            self.clustercty['similarity_score'] = similarity_scores
            
            # L·ªçc c√¥ng ty
            matched = self.clustercty[
                (self.clustercty['cluster'] == predicted_cluster) & 
                (self.clustercty['similarity_score'] >= threshold)
            ].copy()
            
            matched = matched.sort_values(by='similarity_score', ascending=False).head(10)
            
            return matched, predicted_cluster
            
        except Exception as e:
            st.error(f"‚ùå L·ªói ƒë·ªÅ xu·∫•t: {e}")
            return pd.DataFrame(), -1
    
    def get_companies_by_cluster_sentiment(self, cluster_id=None, sentiment=None):
        """L·∫•y c√¥ng ty theo cluster v√† sentiment"""
        if self.clustercty is None:
            return pd.DataFrame()
        
        filtered_data = self.clustercty.copy()
        
        if cluster_id is not None:
            filtered_data = filtered_data[filtered_data['cluster'] == cluster_id]
        
        if sentiment is not None:
            filtered_data = filtered_data[filtered_data['sentiment_group'] == sentiment]
        
        return filtered_data

    def load_gensim_models(self):
        """Load pre-trained Gensim models"""
        try:
            # Gensim Problem 1
            if os.path.exists("gensim_dictionary.pkl"):
                with open("gensim_dictionary.pkl", "rb") as f:
                    self.gensim_dictionary = pickle.load(f)
                with open("gensim_corpus.pkl", "rb") as f:
                    self.gensim_corpus = pickle.load(f)
                self.gensim_tfidf = models.TfidfModel.load("gensim_tfidf_model.tfidf")
                self.gensim_index = similarities.SparseMatrixSimilarity.load("gensim_similarity.index")
                
                # Gensim Problem 2
                with open("gensim_dictionary_2.pkl", "rb") as f:
                    self.gensim_dictionary_2 = pickle.load(f)
                self.gensim_tfidf_2 = models.TfidfModel.load("gensim_tfidf_model_2.tfidf")
                self.gensim_index_2 = similarities.SparseMatrixSimilarity.load("gensim_similarity_2.index")
                
                return True
            else:
                st.warning("‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y Gensim models. Vui l√≤ng train models tr∆∞·ªõc.")
                return False
        except Exception as e:
            st.error(f"‚ùå L·ªói load Gensim models: {e}")
            return False

    def load_cosine_models(self):
        """Load pre-trained Cosine Similarity models"""
        try:
            if os.path.exists("cosine_index.pkl"):
                with open("cosine_index.pkl", "rb") as f:
                    self.cosine_index = pickle.load(f)
                with open("cosine_tfidf_2.pkl", "rb") as f:
                    self.cosine_tfidf_2 = pickle.load(f)
                with open("cosine_tfidf_matrix_2.pkl", "rb") as f:
                    self.cosine_tfidf_matrix_2 = pickle.load(f)
                return True
            else:
                st.warning("‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y Cosine models. Vui l√≤ng train models tr∆∞·ªõc.")
                return False
        except Exception as e:
            st.error(f"‚ùå L·ªói load Cosine models: {e}")
            return False

    def find_similar_companies_gensim(self, company_id, top_n=5):
        """T√¨m c√¥ng ty t∆∞∆°ng t·ª± b·∫±ng Gensim - Problem 1"""
        try:
            if not hasattr(self, 'gensim_tfidf'):
                st.error("‚ùå Gensim models ch∆∞a ƒë∆∞·ª£c load!")
                return pd.DataFrame(), []
            
            # L·∫•y vector TF-IDF c·ªßa c√¥ng ty ƒë∆∞·ª£c ch·ªçn
            tfidf_vec = self.gensim_tfidf[self.gensim_corpus[company_id]]
            
            # T√≠nh cosine similarity
            sims = self.gensim_index[tfidf_vec]
            
            # S·∫Øp x·∫øp v√† l·∫•y top N
            top_similar = sorted([(i, sim) for i, sim in enumerate(sims) if i != company_id], 
                               key=lambda x: x[1], reverse=True)[:top_n]
            
            # L·∫•y d·ªØ li·ªáu
            company_ids = [i[0] for i in top_similar]
            similarities = [round(i[1], 4) for i in top_similar]
            
            df_result = self.clustercty.iloc[company_ids].copy()
            df_result['similarity'] = similarities
            
            return df_result, top_similar
            
        except Exception as e:
            st.error(f"‚ùå L·ªói Gensim similarity: {e}")
            return pd.DataFrame(), []

    def search_companies_gensim(self, query_text, top_n=5):
        """T√¨m ki·∫øm c√¥ng ty b·∫±ng Gensim - Problem 2"""
        try:
            if not hasattr(self, 'gensim_tfidf_2'):
                st.error("‚ùå Gensim search models ch∆∞a ƒë∆∞·ª£c load!")
                return pd.DataFrame(), []
            
            # L√†m s·∫°ch v√† t√°ch t·ª´
            clean_text = self.text_processor.clean_pipeline(query_text)
            tokens = clean_text.split()
            
            # Chuy·ªÉn sang vector BoW
            bow_vector = self.gensim_dictionary_2.doc2bow(tokens)
            
            # Chuy·ªÉn sang TF-IDF
            tfidf_vector = self.gensim_tfidf_2[bow_vector]
            
            # T√≠nh ƒë·ªô t∆∞∆°ng t·ª±
            sims = self.gensim_index_2[tfidf_vector]
            
            # S·∫Øp x·∫øp v√† l·∫•y top N
            top_similar = sorted(enumerate(sims), key=lambda x: x[1], reverse=True)[:top_n]
            
            # L·∫•y d·ªØ li·ªáu
            company_ids = [i[0] for i in top_similar]
            similarities = [round(i[1], 4) for i in top_similar]
            
            df_result = self.clustercty.iloc[company_ids].copy()
            df_result['similarity'] = similarities
            
            return df_result, top_similar
            
        except Exception as e:
            st.error(f"‚ùå L·ªói Gensim search: {e}")
            return pd.DataFrame(), []

    def find_similar_companies_cosine(self, company_id, top_n=5):
        """T√¨m c√¥ng ty t∆∞∆°ng t·ª± b·∫±ng Cosine Similarity - Problem 1"""
        try:
            if not hasattr(self, 'cosine_index'):
                st.error("‚ùå Cosine models ch∆∞a ƒë∆∞·ª£c load!")
                return pd.DataFrame(), []
            
            # B·ªè ch√≠nh n√≥ ra
            sim_scores = self.cosine_index[company_id].copy()
            sim_scores[company_id] = -1
            
            # L·∫•y top N
            similar_indices = sim_scores.argsort()[-top_n:][::-1]
            
            # T·∫°o k·∫øt qu·∫£
            top_similar = [(i, sim_scores[i]) for i in similar_indices]
            df_result = self.clustercty.iloc[similar_indices].copy()
            df_result["similarity"] = [sim_scores[i] for i in similar_indices]
            
            return df_result, top_similar
            
        except Exception as e:
            st.error(f"‚ùå L·ªói Cosine similarity: {e}")
            return pd.DataFrame(), []

    def search_companies_cosine(self, query_text, top_n=5):
        """T√¨m ki·∫øm c√¥ng ty b·∫±ng Cosine Similarity - Problem 2"""
        try:
            if not hasattr(self, 'cosine_tfidf_2'):
                st.error("‚ùå Cosine search models ch∆∞a ƒë∆∞·ª£c load!")
                return pd.DataFrame(), []
            
            # L√†m s·∫°ch query
            cleaned_query = self.text_processor.clean_pipeline(query_text)
            
            # Chuy·ªÉn th√†nh vector TF-IDF
            query_vector = self.cosine_tfidf_2.transform([cleaned_query])
            
            # T√≠nh ƒë·ªô t∆∞∆°ng ƒë·ªìng cosine
            sims = cosine_similarity(query_vector, self.cosine_tfidf_matrix_2)[0]
            
            # L·∫•y top N
            similar_indices = sims.argsort()[-top_n:][::-1]
            
            # T·∫°o k·∫øt qu·∫£
            top_similar = [(sims[i], i) for i in similar_indices]
            df_result = self.clustercty.iloc[similar_indices].copy()
            df_result["similarity_score"] = [sims[i] for i in similar_indices]
            
            return df_result, top_similar
            
        except Exception as e:
            st.error(f"‚ùå L·ªói Cosine search: {e}")
            return pd.DataFrame(), []

    def suggest_company_name(self):
        """T·∫°o selectbox cho vi·ªác ch·ªçn c√¥ng ty"""
        if self.clustercty is None or self.clustercty.empty:
            return None, None
        
        # T·∫°o mapping: t√™n c√¥ng ty ‚Üí index
        company_mapping = {}
        for idx, row in self.clustercty.iterrows():
            company_mapping[row['Company Name']] = idx
        
        # T·∫°o danh s√°ch t√™n c√¥ng ty
        company_list = sorted(company_mapping.keys())
        
        # T·∫°o selectbox
        selected_name = st.selectbox(
            "üè¢ Ch·ªçn c√¥ng ty:",
            options=company_list,
            key="company_selector"
        )
        
        # L·∫•y index t∆∞∆°ng ·ª©ng
        selected_id = company_mapping.get(selected_name, None)
        return selected_name, selected_id

    def show_company_detail(self, data, title=None, expanded=False):
        """Hi·ªÉn th·ªã chi ti·∫øt c√¥ng ty"""
        with st.expander(title or f"{data['Company Name']}", expanded=expanded):
            col1, col2 = st.columns(2)
            
            with col1:
                st.markdown(f"**üè≠ Ng√†nh:** {data.get('Company industry', 'N/A')}")
                st.markdown(f"**üë• Quy m√¥:** {data.get('Company size', 'N/A')}")
                st.markdown(f"**üåç Qu·ªëc gia:** {data.get('Country', 'N/A')}")
                st.markdown(f"**üè¢ Lo·∫°i:** {data.get('Company Type', 'N/A')}")
            
            with col2:
                st.markdown(f"**üìÖ L√†m vi·ªác:** {data.get('Working days', 'N/A')}")
                st.markdown(f"**‚è∞ OT Policy:** {data.get('Overtime Policy', 'N/A')}")
                st.markdown(f"**üòä Sentiment:** {data.get('sentiment_group', 'N/A')}")
                st.markdown(f"**üîë Keywords:** {data.get('keyword', 'N/A')}")
            
            if 'Company overview_new' in data:
                st.markdown("**üìù M√¥ t·∫£ c√¥ng ty:**")
                st.write(data.get('Company overview_new', 'Kh√¥ng c√≥ th√¥ng tin'))
            
            if "Why you'll love working here_new" in data:
                st.markdown("**üíù T·∫°i sao b·∫°n s·∫Ω y√™u th√≠ch:**")
                st.write(data.get("Why you'll love working here_new", 'Kh√¥ng c√≥ th√¥ng tin'))
            
            if 'Our key skills_new' in data:
                st.markdown("**üîß K·ªπ nƒÉng c·∫ßn thi·∫øt:**")
                st.write(data.get('Our key skills_new', 'Kh√¥ng c√≥ th√¥ng tin'))

import subprocess
class PySparkMLSystem:
    def __init__(self):
        self.spark = None
        self.spark_df_ml = None
        self.pyspark_results = {}

# Sidebar
st.sidebar.markdown("## ü§ñ AI Company Recommendation System")
st.sidebar.markdown("---")

# Menu categories
menu_options = ["Business Objective", "Company Suggest", "Build Project", "New Prediction"]
selected_menu = st.sidebar.selectbox("üìã Select Category:", menu_options)

# Th√¥ng tin ng∆∞·ªùi t·∫°o
st.sidebar.markdown("---")
st.sidebar.markdown("### üë• Creators Information")
st.sidebar.markdown("**Creator 1:**")
st.sidebar.markdown("üìß V√µ Minh Tr√≠")
st.sidebar.markdown("‚úâÔ∏è trivm203@gmail.com")
st.sidebar.markdown("**Creator 2:**") 
st.sidebar.markdown("üìß Ph·∫°m Th·ªã Thu Th·∫£o")
st.sidebar.markdown("‚úâÔ∏è phamthithuthao@email.com")

# Main content
if selected_menu == "Business Objective":
    st.markdown('<h1 class="main-header">üéØ Business Objective</h1>', unsafe_allow_html=True)
    
    st.markdown("""
    <div class="section-header">M·ª•c ti√™u c·ªßa d·ª± √°n</div>
    
    H·ªá th·ªëng ƒë·ªÅ xu·∫•t c√¥ng ty n√†y ƒë∆∞·ª£c ph√°t tri·ªÉn nh·∫±m:
    
    ### üéØ M·ª•c ti√™u ch√≠nh:
    - **H·ªó tr·ª£ ·ª©ng vi√™n**: Gi√∫p ·ª©ng vi√™n t√¨m ki·∫øm c√¥ng ty ph√π h·ª£p v·ªõi mong mu·ªën v√† k·ªπ nƒÉng c·ªßa h·ªç
    - **T·ªëi ∆∞u h√≥a tuy·ªÉn d·ª•ng**: C·∫£i thi·ªán qu√° tr√¨nh matching gi·ªØa ·ª©ng vi√™n v√† nh√† tuy·ªÉn d·ª•ng
    - **Ph√¢n t√≠ch th·ªã tr∆∞·ªùng**: Cung c·∫•p insights v·ªÅ xu h∆∞·ªõng tuy·ªÉn d·ª•ng v√† y√™u c·∫ßu c√¥ng vi·ªác
    
    ### üîç T√≠nh nƒÉng ch√≠nh:
    1. **Ph√¢n t√≠ch c√¥ng ty**: Cung c·∫•p th√¥ng tin chi ti·∫øt v·ªÅ c√°c c√¥ng ty h√†ng ƒë·∫ßu
    2. **ƒê·ªÅ xu·∫•t th√¥ng minh**: S·ª≠ d·ª•ng machine learning ƒë·ªÉ ƒë·ªÅ xu·∫•t c√¥ng ty ph√π h·ª£p
    3. **So s√°nh c√¥ng ty**: Gi√∫p ·ª©ng vi√™n so s√°nh c√°c l·ª±a ch·ªçn kh√°c nhau
    4. **D·ª± ƒëo√°n xu h∆∞·ªõng**: Ph√¢n t√≠ch v√† d·ª± ƒëo√°n xu h∆∞·ªõng tuy·ªÉn d·ª•ng
    
    ### üìä L·ª£i √≠ch:
    - Ti·∫øt ki·ªám th·ªùi gian t√¨m ki·∫øm vi·ªác l√†m
    - TƒÉng t·ª∑ l·ªá match th√†nh c√¥ng
    - Cung c·∫•p th√¥ng tin minh b·∫°ch v·ªÅ th·ªã tr∆∞·ªùng lao ƒë·ªông
    - H·ªó tr·ª£ quy·∫øt ƒë·ªãnh ngh·ªÅ nghi·ªáp
    
    ### ü§ñ AI Features:
    - **Vietnamese Text Processing**: X·ª≠ l√Ω vƒÉn b·∫£n ti·∫øng Vi·ªát v·ªõi teencode, stopwords
    - **TF-IDF Vectorization**: Chuy·ªÉn ƒë·ªïi vƒÉn b·∫£n th√†nh vector s·ªë
    - **K-means Clustering**: Ph√¢n nh√≥m c√¥ng ty theo ƒë·∫∑c ƒëi·ªÉm
    - **Multiple ML Models**: Random Forest, SVM, Logistic Regression, etc.
    - **Cosine Similarity**: T√≠nh to√°n ƒë·ªô t∆∞∆°ng ƒë·ªìng th√¥ng minh
    """, unsafe_allow_html=True)

elif selected_menu == "Company Suggest":
    st.markdown('<h1 class="main-header">üè¢ Company Suggestions</h1>', unsafe_allow_html=True)

    # Load d·ªØ li·ªáu n·∫øu ch∆∞a load
    if not st.session_state.data_loaded:
        with st.spinner("üîÑ ƒêang load d·ªØ li·ªáu..."):
            ml_system = CompanyRecommendationSystem()
            if ml_system.load_data():
                ml_system.load_gensim_models()
                ml_system.load_cosine_models()
                st.session_state.ml_system = ml_system
                st.session_state.data_loaded = True
            else:
                st.stop()

    ml_system = st.session_state.ml_system

    tab1, tab2, tab3 = st.tabs(["üß† Gensim Recommendation", "üìä Cosine Similarity", "üîç Smart Text Search"])

    # ---------------------- TAB 1: Gensim Recommendation ---------------------- #
    with tab1:
        st.markdown("### üß† ƒê·ªÅ xu·∫•t c√¥ng ty b·∫±ng Gensim")

        selected_company = st.selectbox("üè¢ Ch·ªçn c√¥ng ty:", ml_system.clustercty['Company Name'].unique())
        top_n = st.slider("üî¢ S·ªë c√¥ng ty ƒë·ªÅ xu·∫•t:", 1, 10, 5)

        if st.button("üîç T√¨m c√¥ng ty t∆∞∆°ng t·ª± (Gensim)", key="gensim_button"):
            st.markdown("---")
            selected_id = ml_system.clustercty[ml_system.clustercty['Company Name'] == selected_company].index[0]

            st.markdown("### üè¢ C√¥ng ty ƒë∆∞·ª£c ch·ªçn:")
            ml_system.show_company_detail(ml_system.clustercty.loc[selected_id], expanded=True)

            df_result, _ = ml_system.find_similar_companies_gensim(selected_id, top_n)
            if not df_result.empty:
                st.markdown("### ü§ù C√°c c√¥ng ty t∆∞∆°ng t·ª±:")
                for idx, row in df_result.iterrows():
                    ml_system.show_company_detail(row, title=f"#{idx+1} {row['Company Name']} - Similarity: {row['similarity']:.3f}")
            else:
                st.info("‚ùå Kh√¥ng t√¨m th·∫•y c√¥ng ty t∆∞∆°ng t·ª±.")

    # ---------------------- TAB 2: Cosine Similarity Search ---------------------- #
    with tab2:
        st.markdown("### üìä T√¨m c√¥ng ty t∆∞∆°ng t·ª± b·∫±ng m√¥ t·∫£ (Cosine Similarity)")

        query_text = st.text_area("üìù Nh·∫≠p m√¥ t·∫£ c√¥ng ty mong mu·ªën:", placeholder="V√≠ d·ª•: m√¥i tr∆∞·ªùng nƒÉng ƒë·ªông, c√¥ng ngh·ªá m·ªõi, AI, machine learning...")
        top_n_cosine = st.slider("üî¢ S·ªë c√¥ng ty t∆∞∆°ng t·ª±:", 1, 10, 5)

        if st.button("üîç T√¨m theo m√¥ t·∫£ (Cosine)", key="cosine_button"):
            if query_text.strip():
                df_result, _ = ml_system.search_companies_cosine(query_text, top_n_cosine)

                if not df_result.empty:
                    st.markdown("### üîé K·∫øt qu·∫£ t∆∞∆°ng t·ª±:")
                    for idx, row in df_result.iterrows():
                        ml_system.show_company_detail(row, title=f"#{idx+1} {row['Company Name']} - Similarity: {row['similarity_score']:.3f}")
                else:
                    st.warning("‚ùå Kh√¥ng t√¨m th·∫•y c√¥ng ty ph√π h·ª£p.")

    with tab3:
        st.markdown("### üîç T√¨m c√¥ng ty theo t·ª´ kh√≥a")

        keyword_query = st.text_input("T√¨m theo t·ª´ kh√≥a:", placeholder="V√≠ d·ª•: fintech, AI, c√¥ng ngh·ªá, l∆∞∆°ng cao...")

        if keyword_query.strip():
            cleaned_query = ml_system.text_processor.clean_pipeline(keyword_query)
            query_words = set(cleaned_query.split())

            search_results = ml_system.clustercty.copy()
            search_results['search_score'] = 0

            for idx, row in search_results.iterrows():
                combined_text = ' '.join([
                    row.get('Company overview_new', ''),
                    row.get('Our key skills_new', ''),
                    row.get("Why you'll love working here_new", ''),
                    row.get('keyword', '')
                ])
                cleaned = ml_system.text_processor.clean_pipeline(combined_text)
                words = set(cleaned.split())
                search_results.at[idx, 'search_score'] = len(words.intersection(query_words)) / len(query_words)

            top_matches = search_results[search_results['search_score'] > 0]
            top_matches = top_matches.sort_values(by='search_score', ascending=False).head(10)

            if not top_matches.empty:
                st.markdown("### ‚úÖ K·∫øt qu·∫£ t√¨m th·∫•y:")
                for idx, row in top_matches.iterrows():
                    ml_system.show_company_detail(row, title=f"#{idx+1} {row['Company Name']} - Score: {row['search_score']:.3f}")
            else:
                st.warning("Kh√¥ng t√¨m th·∫•y c√¥ng ty n√†o ch·ª©a t·ª´ kh√≥a ph√π h·ª£p.")

elif selected_menu == "Build Project":
    st.markdown('<h1 class="main-header">üî® Build Project</h1>', unsafe_allow_html=True)

    try:
        with open("saved_model/training_meta.json", "r", encoding="utf-8") as f:
            training_meta = json.load(f)
        sklearn_df = pd.read_csv("saved_model/sklearn_results.csv")
        with open("saved_model/pyspark_results.json", "r", encoding="utf-8") as f:
            pyspark_results = json.load(f)
        with open("saved_model/cluster_data.pkl", "rb") as f:
            clustercty = pickle.load(f)

        st.success("‚úÖ ƒê√£ load k·∫øt qu·∫£ t·ª´ m√¥ h√¨nh ƒë√£ train!")

        # Hi·ªÉn th·ªã metric t·ªïng quan
        col1, col2, col3, col4 = st.columns(4)
        with col1:
            st.metric("üìä T·ªïng c√¥ng ty", len(clustercty))
        with col2:
            st.metric("üéØ S·ªë cluster", clustercty['cluster'].nunique())
        with col3:
            st.metric("üèÜ Best model", training_meta["best_model"])
        with col4:
            st.metric("üìà Accuracy", f"{training_meta['best_accuracy'] * 100:.2f}%")

        # Hi·ªÉn th·ªã b·∫£ng v√† bi·ªÉu ƒë·ªì
        st.markdown("### üìä So s√°nh c√°c m√¥ h√¨nh")
        st.image("saved_model/comparison_all_models.png", caption="So s√°nh m√¥ h√¨nh Sklearn & PySpark", use_column_width=True)

        st.markdown("### üç∞ Ph√¢n b·ªë c√¥ng ty theo Cluster")
        st.image("saved_model/cluster_distribution_pie.png", caption="T·ª∑ l·ªá c√°c c·ª•m c√¥ng ty", use_column_width=True)

        st.markdown("### üîç K·∫øt qu·∫£ chi ti·∫øt:")
        st.subheader("üî¨ Sklearn Models")
        sklearn_df = pd.read_csv("saved_model/sklearn_results.csv", index_col=0)
        sklearn_df.reset_index(inplace=True)
        sklearn_df.rename(columns={"index": "Model"}, inplace=True)
        sklearn_df["Accuracy (%)"] = sklearn_df["Sklearn Accuracy"] * 100
        st.dataframe(sklearn_df[["Model", "Sklearn Accuracy", "Accuracy (%)"]], use_container_width=True)



        st.subheader("‚ö° PySpark Models")
        pyspark_df = pd.DataFrame.from_dict(pyspark_results, orient="index", columns=["Accuracy"])
        pyspark_df["Accuracy (%)"] = pyspark_df["Accuracy"] * 100
        st.dataframe(pyspark_df[["Accuracy (%)"]], use_container_width=True)

    except Exception as e:
        st.error(f"‚ùå Kh√¥ng th·ªÉ load k·∫øt qu·∫£: {e}")
        st.info("üìå Vui l√≤ng ch·∫°y file `train_and_save_model.py` tr∆∞·ªõc.")


elif selected_menu == "New Prediction":
    st.markdown('<h1 class="main-header">üîÆ New Prediction</h1>', unsafe_allow_html=True)

    try:
        # Load c√°c th√†nh ph·∫ßn ƒë√£ hu·∫•n luy·ªán
        with open("saved_model/best_model.pkl", "rb") as f:
            best_model = pickle.load(f)
        with open("saved_model/tfidf.pkl", "rb") as f:
            tfidf = pickle.load(f)
        with open("saved_model/pca.pkl", "rb") as f:
            pca = pickle.load(f)
        with open("saved_model/encoded_columns.pkl", "rb") as f:
            encoded_columns = pickle.load(f)
        with open("saved_model/cluster_data.pkl", "rb") as f:
            clustercty = pickle.load(f)

        processor = TextProcessor()
        st.success("‚úÖ M√¥ h√¨nh v√† d·ªØ li·ªáu ƒë√£ ƒë∆∞·ª£c t·∫£i th√†nh c√¥ng!")

        # Nh·∫≠p input t·ª´ ng∆∞·ªùi d√πng
        col1, col2 = st.columns(2)
        with col1:
            company_type = st.selectbox("üè¢ Lo·∫°i c√¥ng ty", clustercty['Company Type'].unique())
            company_industry = st.selectbox("üè≠ Ng√†nh ngh·ªÅ", clustercty['Company industry'].unique())
            company_size = st.selectbox("üë• Quy m√¥", clustercty['Company size'].unique())
        with col2:
            country = st.selectbox("üåç Qu·ªëc gia", clustercty['Country'].unique())
            working_days = st.selectbox("üìÖ Ng√†y l√†m vi·ªác", clustercty['Working days'].unique())
            ot_policy = st.selectbox("‚è∞ Ch√≠nh s√°ch OT", clustercty['Overtime Policy'].unique())

        text_input = st.text_area("üìù M√¥ t·∫£ mong mu·ªën c·ªßa b·∫°n:",
        placeholder="V√≠ d·ª•: T√¥i mu·ªën l√†m vi·ªác trong m√¥i tr∆∞·ªùng c√¥ng ngh·ªá, s·ª≠ d·ª•ng AI v√† machine learning, c√≥ c∆° h·ªôi ph√°t tri·ªÉn...",
        height=100)
        threshold = st.slider("üéØ Ng∆∞·ª°ng ƒë·ªô t∆∞∆°ng ƒë·ªìng:", 0.0, 1.0, 0.1, 0.05)

        if st.button("üîç ƒê·ªÅ xu·∫•t c√¥ng ty", use_container_width=True):
            if not text_input.strip():
                st.warning("‚ö†Ô∏è Vui l√≤ng nh·∫≠p m√¥ t·∫£ mong mu·ªën c·ªßa b·∫°n.")
                st.stop()

            with st.spinner("ü§ñ AI ƒëang ph√¢n t√≠ch..."):
                cleaned_text = processor.clean_pipeline(text_input)
                text_vec = tfidf.transform([cleaned_text])

                input_df = pd.DataFrame([{
                    "Company Type": company_type,
                    "Company industry": company_industry,
                    "Company size": company_size,
                    "Country": country,
                    "Working days": working_days,
                    "Overtime Policy": ot_policy
                }])
                input_encoded = pd.get_dummies(input_df)
                for col in encoded_columns:
                    if col not in input_encoded.columns:
                        input_encoded[col] = 0
                input_encoded = input_encoded[encoded_columns]

                X_full = pd.concat([
                    input_encoded.reset_index(drop=True),
                    pd.DataFrame(text_vec.toarray(), columns=tfidf.get_feature_names_out())
                ], axis=1)
                X_pca = pca.transform(X_full)
                pred_cluster = best_model.predict(X_pca)[0]

                from sklearn.metrics.pairwise import cosine_similarity
                all_vecs = tfidf.transform(clustercty["combined_text"])
                sim_scores = cosine_similarity(text_vec, all_vecs).flatten()

                clustercty["similarity_score"] = sim_scores
                matched = clustercty[(clustercty["cluster"] == pred_cluster) & (clustercty["similarity_score"] >= threshold)]
                matched = matched.sort_values(by="similarity_score", ascending=False).head(10)

                if not matched.empty:
                    st.markdown(f"""
                    <div class="prediction-container">
                        <h3>üéØ K·∫øt qu·∫£ D·ª± ƒëo√°n</h3>
                        <p><strong>Cluster ƒë∆∞·ª£c d·ª± ƒëo√°n:</strong> {pred_cluster}</p>
                        <p><strong>S·ªë c√¥ng ty ph√π h·ª£p:</strong> {len(matched)}</p>
                        <p><strong>Ng∆∞·ª°ng t∆∞∆°ng ƒë·ªìng:</strong> {threshold}</p>
                    </div>
                    """, unsafe_allow_html=True)

                    st.markdown("### üèÜ C√°c c√¥ng ty ƒë∆∞·ª£c ƒë·ªÅ xu·∫•t:")

                    # üí° D√πng l·∫°i show_company_detail()
                    ml_system = CompanyRecommendationSystem()
                    ml_system.clustercty = clustercty  # truy·ªÅn data v√†o class ƒë·ªÉ hi·ªÉn th·ªã n·ªôi dung

                    for idx, row in matched.iterrows():
                        ml_system.show_company_detail(
                            row,
                            title=f"#{idx+1} {row['Company Name']} - Similarity: {row['similarity_score']:.3f}",
                            expanded=False
                        )

                    if len(matched) > 1:
                        st.markdown("### üìä Bi·ªÉu ƒë·ªì ƒë·ªô t∆∞∆°ng ƒë·ªìng:")
                        fig = px.bar(
                            matched,
                            x="Company Name",
                            y="similarity_score",
                            title="üéØ ƒê·ªô t∆∞∆°ng ƒë·ªìng c√°c c√¥ng ty ƒë∆∞·ª£c ƒë·ªÅ xu·∫•t",
                            labels={'x': 'C√¥ng ty', 'y': 'ƒê·ªô t∆∞∆°ng ƒë·ªìng'}
                        )
                        fig.update_layout(xaxis_tickangle=-45)
                        st.plotly_chart(fig, use_container_width=True)
                else:
                    st.warning("‚ùå Kh√¥ng t√¨m th·∫•y c√¥ng ty ph√π h·ª£p v·ªõi ti√™u ch√≠ ƒë√£ ch·ªçn.")

    except Exception as e:
        st.error(f"‚ùå L·ªói khi t·∫£i m√¥ h√¨nh ho·∫∑c d·ªØ li·ªáu: {e}")



