import streamlit as st
import pandas as pd
import numpy as np
import plotly.express as px
import plotly.graph_objects as go
import re
import string
import os
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.decomposition import PCA
from sklearn.cluster import KMeans
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.naive_bayes import GaussianNB
from sklearn.svm import SVC
from sklearn.tree import DecisionTreeClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import accuracy_score, classification_report, silhouette_score
from sklearn.model_selection import train_test_split
from sklearn.metrics.pairwise import cosine_similarity
import pickle
from gensim import corpora, models, similarities

try:
    from pyspark.sql import SparkSession
    from pyspark.sql.types import StructType, StructField, IntegerType, StringType, DoubleType
    from pyspark.ml.feature import VectorAssembler, StringIndexer
    from pyspark.ml.classification import LogisticRegression as SparkLogisticRegression, DecisionTreeClassifier as SparkDecisionTreeClassifier
    from pyspark.ml.evaluation import MulticlassClassificationEvaluator
    from pyspark.ml import Pipeline
    PYSPARK_AVAILABLE = True
except ImportError:
    PYSPARK_AVAILABLE = False

# C·∫•u h√¨nh trang
st.set_page_config(
    page_title="AI Company Recommendation System AT IT_Viec",
    page_icon="ü§ñ",
    layout="wide",
    initial_sidebar_state="expanded"
)

# CSS t√πy ch·ªânh
st.markdown("""
<style>
    .main-header {
        font-size: 2.5rem;
        font-weight: bold;
        color: #1f77b4;
        text-align: center;
        margin-bottom: 2rem;
    }
    .section-header {
        font-size: 1.8rem;
        font-weight: bold;
        color: #2c3e50;
        margin-bottom: 1rem;
    }
    .company-card {
        background-color: #f8f9fa;
        padding: 1rem;
        border-radius: 10px;
        border-left: 4px solid #1f77b4;
        margin-bottom: 1rem;
    }
    .cluster-card {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        padding: 1.5rem;
        border-radius: 15px;
        color: white;
        margin-bottom: 1rem;
    }
    .sentiment-positive {
        background-color: #d4edda;
        border-left: 4px solid #28a745;
        padding: 1rem;
        border-radius: 8px;
        margin-bottom: 1rem;
    }
    .sentiment-negative {
        background-color: #f8d7da;
        border-left: 4px solid #dc3545;
        padding: 1rem;
        border-radius: 8px;
        margin-bottom: 1rem;
    }
    .sentiment-neutral {
        background-color: #fff3cd;
        border-left: 4px solid #ffc107;
        padding: 1rem;
        border-radius: 8px;
        margin-bottom: 1rem;
    }
    .prediction-container {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        padding: 2rem;
        border-radius: 15px;
        color: white;
        margin-bottom: 2rem;
    }
    .success-box {
        background-color: #d4edda;
        border: 1px solid #c3e6cb;
        color: #155724;
        padding: 1rem;
        border-radius: 5px;
        margin: 1rem 0;
    }
    .warning-box {
        background-color: #fff3cd;
        border: 1px solid #ffeaa7;
        color: #856404;
        padding: 1rem;
        border-radius: 5px;
        margin: 1rem 0;
    }
    .error-box {
        background-color: #f8d7da;
        border: 1px solid #f5c6cb;
        color: #721c24;
        padding: 1rem;
        border-radius: 5px;
        margin: 1rem 0;
    }
</style>
""", unsafe_allow_html=True)

# Kh·ªüi t·∫°o session state
if 'data_loaded' not in st.session_state:
    st.session_state.data_loaded = False
if 'model_trained' not in st.session_state:
    st.session_state.model_trained = False

# Class x·ª≠ l√Ω vƒÉn b·∫£n t√≠ch h·ª£p t·ª´ code c·ªßa b·∫°n
class TextProcessor:
    def __init__(self):
        self.teen_dict = {}
        self.stopwords_lst = []
        self.wrong_lst = []
        self.load_dictionaries()
    
    def load_dictionaries(self):
        """Load c√°c t·ª´ ƒëi·ªÉn x·ª≠ l√Ω vƒÉn b·∫£n t·ª´ files ho·∫∑c fallback"""
        try:
            # Load teencode t·ª´ file ho·∫∑c fallback
            teencode_paths = ['files/teencode.txt', 'teencode.txt']
            for path in teencode_paths:
                if os.path.exists(path):
                    with open(path, 'r', encoding="utf8") as file:
                        teen_lst = file.read().split('\n')
                        for line in teen_lst:
                            if '\t' in line:
                                key, value = line.split('\t', 1)
                                self.teen_dict[key] = str(value)
                    break
            else:
                # Fallback teencode dictionary
                self.teen_dict = {
                    'ko': 'kh√¥ng', 'k': 'kh√¥ng', 'dc': 'ƒë∆∞·ª£c', 'vs': 'v·ªõi',
                    'tks': 'thanks', 'ty': 'thank you', 'ok': 'okay', 'oke': 'okay',
                    'bt': 'b√¨nh th∆∞·ªùng', 'nc': 'n√≥i chuy·ªán', 'kb': 'k·∫øt b·∫°n'
                }
            
            # Load stopwords t·ª´ file ho·∫∑c fallback
            stopwords_paths = ['files/vietnamese-stopwords_rev.txt', 'vietnamese-stopwords_rev.txt']
            for path in stopwords_paths:
                if os.path.exists(path):
                    with open(path, 'r', encoding="utf8") as file:
                        self.stopwords_lst = file.read().split('\n')
                    break
            else:
                # Fallback stopwords
                self.stopwords_lst = [
                    'v√†', 'c·ªßa', 'c√≥', 'l√†', 'ƒë∆∞·ª£c', 'trong', 'v·ªõi', 'ƒë·ªÉ', 'cho', 't·ª´',
                    'm·ªôt', 'c√°c', 'n√†y', 'ƒë√≥', 'nh·ªØng', 'nhi·ªÅu', 'r·∫•t', 'c≈©ng', 's·∫Ω',
                    'ƒë√£', 'ƒëang', 'v·ªÅ', 'theo', 'nh∆∞', 'khi', 'n·∫øu', 'v√¨', 'do', 'b·ªüi'
                ]
            
            # Load wrong words t·ª´ file ho·∫∑c fallback
            wrong_words_paths = ['files/wrong-word_rev.txt', 'wrong-word_rev.txt']
            for path in wrong_words_paths:
                if os.path.exists(path):
                    with open(path, 'r', encoding="utf8") as file:
                        self.wrong_lst = file.read().split('\n')
                    break
            else:
                self.wrong_lst = ['zzz', 'xxx', 'aaa', 'bbb', 'ccc']
                    
        except Exception as e:
            st.warning(f"‚ö†Ô∏è Kh√¥ng th·ªÉ load m·ªôt s·ªë file t·ª´ ƒëi·ªÉn: {e}")
    
    def clean_text(self, text):
        """L√†m s·∫°ch vƒÉn b·∫£n c∆° b·∫£n - t√≠ch h·ª£p t·ª´ code c·ªßa b·∫°n"""
        if not text or pd.isna(text):
            return ""
        text = str(text).lower()  # Hoa -> th∆∞·ªùng
        text = re.sub(rf"[{string.punctuation}]", "", text)  # B·ªè d·∫•u c√¢u
        text = re.sub(r"\b(g|ml)\b", "", text)  # B·ªè t·ª´ 'g' ho·∫∑c 'ml' khi n√≥ l√† c·∫£ t·ª´
        text = re.sub(r"\s+", " ", text).strip()  # X√≥a kho·∫£ng tr·∫Øng th·ª´a
        text = re.sub(r"^[\-\+\*\‚Ä¢\‚óè\¬∑\~\‚Äì\‚Äî\>]+", "", text)  # B·ªè d·∫•u ƒë·∫ßu c√¢u
        return text
    
    def fix_teencode(self, text):
        """S·ª≠a teencode - t√≠ch h·ª£p t·ª´ code c·ªßa b·∫°n"""
        words = text.split()
        corrected = [self.teen_dict.get(word, word) for word in words]
        return " ".join(corrected)
    
    def remove_wrongword(self, text):
        """Lo·∫°i b·ªè t·ª´ sai"""
        words = text.split()
        trueword = [word for word in words if word not in self.wrong_lst]
        return " ".join(trueword)
    
    def remove_stopword(self, text):
        """Lo·∫°i b·ªè stopwords - t√≠ch h·ª£p t·ª´ code c·ªßa b·∫°n"""
        words = text.split()
        stopword = [word for word in words if word not in self.stopwords_lst]
        return " ".join(stopword)
    
    def clean_pipeline(self, text):
        """Pipeline x·ª≠ l√Ω vƒÉn b·∫£n ho√†n ch·ªânh - t√≠ch h·ª£p t·ª´ code c·ªßa b·∫°n"""
        if not text or pd.isna(text):
            return ""
        text = self.clean_text(text)
        text = self.fix_teencode(text)
        text = self.remove_wrongword(text)
        text = self.remove_stopword(text)
        return text

# Class h·ªá th·ªëng ML v·ªõi d·ªØ li·ªáu th·ª±c
class CompanyRecommendationSystem:
    def __init__(self):
        self.clustercty = None
        self.tfidf = TfidfVectorizer(max_features=500)
        self.pca = PCA(n_components=50, random_state=42)
        self.best_model = None
        self.df_structured_encoded = None
        self.X_full = None
        self.text_processor = TextProcessor()
        self.structured_cols = ['Company Type', 'Company industry', 'Company size', 'Country', 'Working days', 'Overtime Policy']
        self.text_cols = ['Company overview_new', "Why you'll love working here_new", 'Our key skills_new', 'keyword']
        
    @st.cache_data
    def load_data(_self):
        """Load v√† x·ª≠ l√Ω d·ªØ li·ªáu th·ª±c - KH√îNG t·∫°o sample data"""
        try:
            # ƒê∆∞·ªùng d·∫´n file d·ªØ li·ªáu th·ª±c
            data_paths = {
                'translated_data': 'data/translated_data.csv',
                'top2_clusters': 'data/top2_clusters_per_company.csv', 
                'sentiment_data': 'data/sentiment_by_company.csv'
            }
            
            # Ki·ªÉm tra file t·ªìn t·∫°i
            missing_files = []
            for name, path in data_paths.items():
                if not os.path.exists(path):
                    missing_files.append(path)
            
            if missing_files:
                st.markdown(f"""
                <div class="error-box">
                    <h4>‚ùå Kh√¥ng t√¨m th·∫•y c√°c file d·ªØ li·ªáu c·∫ßn thi·∫øt:</h4>
                    <ul>
                        {''.join([f'<li>{file}</li>' for file in missing_files])}
                    </ul>
                    <p><strong>H∆∞·ªõng d·∫´n:</strong></p>
                    <ol>
                        <li>T·∫°o th∆∞ m·ª•c <code>data/</code> trong project</li>
                        <li>Upload c√°c file CSV v√†o th∆∞ m·ª•c <code>data/</code></li>
                        <li>ƒê·∫£m b·∫£o t√™n file ch√≠nh x√°c nh∆∞ tr√™n</li>
                        <li>Refresh l·∫°i trang</li>
                    </ol>
                </div>
                """, unsafe_allow_html=True)
                return False
            
            # Load d·ªØ li·ªáu th·ª±c
            st.info("üìÇ ƒêang load d·ªØ li·ªáu th·ª±c t·ª´ files...")
            
            with st.spinner("Loading translated_data.csv..."):
                clustercty = pd.read_csv(data_paths['translated_data'])
                st.success(f"‚úÖ Loaded {len(clustercty)} companies from translated_data.csv")
            
            with st.spinner("Loading cluster data..."):
                new_data = pd.read_csv(data_paths['top2_clusters'])
                st.success(f"‚úÖ Loaded {len(new_data)} cluster records")
            
            with st.spinner("Loading sentiment data..."):
                sentiment_cln = pd.read_csv(data_paths['sentiment_data'])
                st.success(f"‚úÖ Loaded {len(sentiment_cln)} sentiment records")
            
            # Ki·ªÉm tra d·ªØ li·ªáu kh√¥ng tr·ªëng
            if clustercty.empty or new_data.empty or sentiment_cln.empty:
                st.error("‚ùå M·ªôt ho·∫∑c nhi·ªÅu file CSV tr·ªëng! Vui l√≤ng ki·ªÉm tra d·ªØ li·ªáu.")
                return False
            
            # Merge d·ªØ li·ªáu theo logic c·ªßa b·∫°n
            st.info("üîó ƒêang merge d·ªØ li·ªáu...")
            new_data = pd.merge(new_data, sentiment_cln[['Company Name','sentiment_group']], on='Company Name', how='left')
            clustercty = clustercty.merge(new_data[['Company Name', 'keyword', 'sentiment_group']], on='Company Name', how='left')
            
            # X·ª≠ l√Ω c·ªôt kh√¥ng c·∫ßn thi·∫øt
            if 'Unnamed: 0' in clustercty.columns:
                clustercty.drop(columns=['Unnamed: 0'], inplace=True)
            
            # ƒêi·ªÅn gi√° tr·ªã null
            clustercty['keyword'].fillna('kh√¥ng x√°c ƒë·ªãnh', inplace=True)
            clustercty['sentiment_group'].fillna('neutral', inplace=True)
            
            # Ki·ªÉm tra c√°c c·ªôt c·∫ßn thi·∫øt
            required_cols = _self.structured_cols + _self.text_cols
            missing_cols = [col for col in required_cols if col not in clustercty.columns]
            
            if missing_cols:
                st.error(f"‚ùå Thi·∫øu c√°c c·ªôt c·∫ßn thi·∫øt: {missing_cols}")
                st.info("üìã C√°c c·ªôt c√≥ s·∫µn: " + ", ".join(clustercty.columns.tolist()))
                return False
            
            # L∆∞u d·ªØ li·ªáu
            _self.clustercty = clustercty
            st.success(f"üéâ Load d·ªØ li·ªáu th√†nh c√¥ng: {len(clustercty)} c√¥ng ty v·ªõi ƒë·∫ßy ƒë·ªß th√¥ng tin!")
            
            # Hi·ªÉn th·ªã th·ªëng k√™
            col1, col2, col3, col4 = st.columns(4)
            with col1:
                st.metric("üìä T·ªïng c√¥ng ty", len(clustercty))
            with col2:
                st.metric("üè≠ S·ªë ng√†nh", clustercty['Company industry'].nunique())
            with col3:
                st.metric("üòä C√≥ sentiment", clustercty['sentiment_group'].notna().sum())
            with col4:
                st.metric("üîë C√≥ keywords", clustercty['keyword'].notna().sum())
            
            return True
            
        except Exception as e:
            st.markdown(f"""
            <div class="error-box">
                <h4>‚ùå L·ªói load d·ªØ li·ªáu:</h4>
                <p><strong>Chi ti·∫øt l·ªói:</strong> {str(e)}</p>
                <p><strong>H∆∞·ªõng d·∫´n kh·∫Øc ph·ª•c:</strong></p>
                <ol>
                    <li>Ki·ªÉm tra format file CSV (UTF-8 encoding)</li>
                    <li>ƒê·∫£m b·∫£o c√°c c·ªôt c·∫ßn thi·∫øt c√≥ trong file</li>
                    <li>Ki·ªÉm tra ƒë∆∞·ªùng d·∫´n file</li>
                    <li>Th·ª≠ load t·ª´ng file ri√™ng l·∫ª ƒë·ªÉ debug</li>
                </ol>
            </div>
            """, unsafe_allow_html=True)
            return False
    
    def prepare_features(self):
        """Chu·∫©n b·ªã features v·ªõi error handling t·ªët h∆°n"""
        try:
            if self.clustercty is None or self.clustercty.empty:
                st.error("‚ùå D·ªØ li·ªáu ch∆∞a ƒë∆∞·ª£c load ho·∫∑c tr·ªëng!")
                return False
            
            st.info("üîß ƒêang chu·∫©n b·ªã features...")
            
            # Ki·ªÉm tra c√°c c·ªôt text
            text_cols_available = [col for col in self.text_cols if col in self.clustercty.columns]
            if not text_cols_available:
                st.error(f"‚ùå Kh√¥ng t√¨m th·∫•y c·ªôt text n√†o trong: {self.text_cols}")
                return False
            
            st.info(f"üìù S·ª≠ d·ª•ng c√°c c·ªôt text: {text_cols_available}")
            
            # X·ª≠ l√Ω vƒÉn b·∫£n v·ªõi text processor
            with st.spinner("ƒêang x·ª≠ l√Ω vƒÉn b·∫£n..."):
                self.clustercty['combined_text'] = self.clustercty[text_cols_available].fillna('').agg(' '.join, axis=1)
                self.clustercty['combined_text'] = self.clustercty['combined_text'].apply(self.text_processor.clean_pipeline)
            
            # Ki·ªÉm tra k·∫øt qu·∫£ x·ª≠ l√Ω text
            if self.clustercty['combined_text'].isna().all():
                st.error("‚ùå T·∫•t c·∫£ combined_text ƒë·ªÅu null sau khi x·ª≠ l√Ω!")
                return False
            
            # TF-IDF
            with st.spinner("ƒêang th·ª±c hi·ªán TF-IDF vectorization..."):
                tfidf_matrix = self.tfidf.fit_transform(self.clustercty['combined_text'])
                df_tfidf = pd.DataFrame(
                    tfidf_matrix.toarray(),
                    columns=self.tfidf.get_feature_names_out()
                )
            
            st.success(f"‚úÖ TF-IDF: {df_tfidf.shape[1]} features")
            
            # Ki·ªÉm tra c√°c c·ªôt structured
            structured_cols_available = [col for col in self.structured_cols if col in self.clustercty.columns]
            if not structured_cols_available:
                st.error(f"‚ùå Kh√¥ng t√¨m th·∫•y c·ªôt structured n√†o trong: {self.structured_cols}")
                return False
            
            st.info(f"üèóÔ∏è S·ª≠ d·ª•ng c√°c c·ªôt structured: {structured_cols_available}")
            
            # One-hot encode
            with st.spinner("ƒêang th·ª±c hi·ªán One-hot encoding..."):
                self.df_structured_encoded = pd.get_dummies(self.clustercty[structured_cols_available], drop_first=True)
            
            st.success(f"‚úÖ One-hot encoding: {self.df_structured_encoded.shape[1]} features")
            
            # G·ªôp d·ªØ li·ªáu
            X_concat = pd.concat([
                self.df_structured_encoded.reset_index(drop=True), 
                df_tfidf.reset_index(drop=True)
            ], axis=1)
            
            st.info(f"üîó Combined features: {X_concat.shape[1]} total features")
            
            # PCA
            with st.spinner("ƒêang th·ª±c hi·ªán PCA dimensionality reduction..."):
                n_components = min(50, X_concat.shape[1] - 1, X_concat.shape[0] - 1)
                self.pca = PCA(n_components=n_components, random_state=42)
                self.X_full = self.pca.fit_transform(X_concat)
            
            st.success(f"‚úÖ PCA completed: {self.X_full.shape[1]} components")
            
            return True
            
        except Exception as e:
            st.error(f"‚ùå L·ªói chu·∫©n b·ªã features: {str(e)}")
            return False
    
    def find_optimal_clusters(self):
        """T√¨m s·ªë cluster t·ªëi ∆∞u"""
        K = range(2, min(11, len(self.clustercty)))
        silhouette_scores = []
        
        progress_bar = st.progress(0)
        status_text = st.empty()
        
        for i, k in enumerate(K):
            status_text.text(f'ƒêang test k={k}...')
            kmeans = KMeans(n_clusters=k, random_state=42)
            labels = kmeans.fit_predict(self.X_full)
            score = silhouette_score(self.X_full, labels)
            silhouette_scores.append(score)
            progress_bar.progress((i + 1) / len(K))
        
        status_text.empty()
        progress_bar.empty()
        
        best_k = K[silhouette_scores.index(max(silhouette_scores))]
        
        # Visualize silhouette scores
        fig = px.line(x=list(K), y=silhouette_scores, 
                     title="Silhouette Score vs Number of Clusters",
                     labels={'x': 'Number of Clusters (k)', 'y': 'Silhouette Score'})
        fig.add_vline(x=best_k, line_dash="dash", line_color="red", 
                     annotation_text=f"Best k={best_k}")
        st.plotly_chart(fig, use_container_width=True)
        
        return best_k, silhouette_scores
    
    def train_models(self):
        """Training c√°c m√¥ h√¨nh"""
        try:
            # T√¨m s·ªë cluster t·ªëi ∆∞u
            best_k, silhouette_scores = self.find_optimal_clusters()
        
            # Clustering v·ªõi k t·ªëi ∆∞u
            final_kmeans = KMeans(n_clusters=best_k, random_state=42)
            cluster_labels = final_kmeans.fit_predict(self.X_full)
            self.clustercty['cluster'] = cluster_labels
        
            # Chia train/test
            X_train, X_test, y_train, y_test = train_test_split(
                self.X_full, cluster_labels, test_size=0.2, random_state=42
            )
        
            # C√°c m√¥ h√¨nh
            models = {
                "Random Forest": RandomForestClassifier(n_estimators=50),
                "Logistic Regression": LogisticRegression(max_iter=500),
                "Naive Bayes": GaussianNB(),
                "Decision Tree": DecisionTreeClassifier(max_depth=10),
                "KNN": KNeighborsClassifier(n_neighbors=3)
            }
        
            results = []
            trained_models = {}
        
            progress_bar = st.progress(0)
            status_text = st.empty()
        
            for i, (name, model) in enumerate(models.items()):
                status_text.text(f'Training {name}...')
                model.fit(X_train, y_train)
                y_pred = model.predict(X_test)
                acc = accuracy_score(y_test, y_pred)
                results.append((name, acc))
                trained_models[name] = model
                progress_bar.progress((i + 1) / len(models))
        
            status_text.empty()
            progress_bar.empty()
            
            # Ch·ªçn m√¥ h√¨nh t·ªët nh·∫•t
            best_model_name, best_acc = max(results, key=lambda x: x[1])
            self.best_model = trained_models[best_model_name]
        
            st.success(f"üèÜ M√¥ h√¨nh t·ªët nh·∫•t: {best_model_name} v·ªõi accuracy: {best_acc:.3f}")
        
            return results, best_model_name, best_acc, best_k
        
        except Exception as e:
            st.error(f"‚ùå L·ªói training models: {e}")
            return [], "", 0, 0
    
    def recommend_companies(self, user_input, text_input, threshold=0.1):
        """ƒê·ªÅ xu·∫•t c√¥ng ty"""
        try:
            # X·ª≠ l√Ω text input
            cleaned_text = self.text_processor.clean_pipeline(text_input)
            tfidf_vec = self.tfidf.transform([cleaned_text])
            
            # X·ª≠ l√Ω structured input
            structured_df = pd.DataFrame([user_input])
            structured_encoded = pd.get_dummies(structured_df)
            
            # ƒê·∫£m b·∫£o c√≥ ƒë·ªß columns
            missing_cols = set(self.df_structured_encoded.columns) - set(structured_encoded.columns)
            for col in missing_cols:
                structured_encoded[col] = 0
            structured_encoded = structured_encoded[self.df_structured_encoded.columns]
            
            # G·ªôp features
            user_input_vector = pd.concat([
                structured_encoded.reset_index(drop=True), 
                pd.DataFrame(tfidf_vec.toarray(), columns=self.tfidf.get_feature_names_out())
            ], axis=1)
            
            # PCA transform
            user_input_pca = self.pca.transform(user_input_vector)
            
            # Predict cluster
            predicted_cluster = self.best_model.predict(user_input_pca)[0]
            
            # T√≠nh Cosine Similarity
            company_text_vectors = self.tfidf.transform(self.clustercty['combined_text'])
            similarity_scores = cosine_similarity(tfidf_vec, company_text_vectors).flatten()
            self.clustercty['similarity_score'] = similarity_scores
            
            # L·ªçc c√¥ng ty
            matched = self.clustercty[
                (self.clustercty['cluster'] == predicted_cluster) & 
                (self.clustercty['similarity_score'] >= threshold)
            ].copy()
            
            matched = matched.sort_values(by='similarity_score', ascending=False).head(10)
            
            return matched, predicted_cluster
            
        except Exception as e:
            st.error(f"‚ùå L·ªói ƒë·ªÅ xu·∫•t: {e}")
            return pd.DataFrame(), -1
    
    def get_companies_by_cluster_sentiment(self, cluster_id=None, sentiment=None):
        """L·∫•y c√¥ng ty theo cluster v√† sentiment"""
        if self.clustercty is None:
            return pd.DataFrame()
        
        filtered_data = self.clustercty.copy()
        
        if cluster_id is not None:
            filtered_data = filtered_data[filtered_data['cluster'] == cluster_id]
        
        if sentiment is not None:
            filtered_data = filtered_data[filtered_data['sentiment_group'] == sentiment]
        
        return filtered_data

    def load_gensim_models(self):
        """Load pre-trained Gensim models"""
        try:
            # Gensim Problem 1
            if os.path.exists("models/gensim_dictionary.pkl"):
                with open("models/gensim_dictionary.pkl", "rb") as f:
                    self.gensim_dictionary = pickle.load(f)
                with open("models/gensim_corpus.pkl", "rb") as f:
                    self.gensim_corpus = pickle.load(f)
                self.gensim_tfidf = models.TfidfModel.load("models/gensim_tfidf_model.tfidf")
                self.gensim_index = similarities.SparseMatrixSimilarity.load("models/gensim_similarity.index")
                
                # Gensim Problem 2
                with open("models/gensim_dictionary_2.pkl", "rb") as f:
                    self.gensim_dictionary_2 = pickle.load(f)
                self.gensim_tfidf_2 = models.TfidfModel.load("models/gensim_tfidf_model_2.tfidf")
                self.gensim_index_2 = similarities.SparseMatrixSimilarity.load("models/gensim_similarity_2.index")
                
                return True
            else:
                st.warning("‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y Gensim models. Vui l√≤ng train models tr∆∞·ªõc.")
                return False
        except Exception as e:
            st.error(f"‚ùå L·ªói load Gensim models: {e}")
            return False

    def load_cosine_models(self):
        """Load pre-trained Cosine Similarity models"""
        try:
            if os.path.exists("models/cosine_index.pkl"):
                with open("models/cosine_index.pkl", "rb") as f:
                    self.cosine_index = pickle.load(f)
                with open("models/cosine_tfidf_2.pkl", "rb") as f:
                    self.cosine_tfidf_2 = pickle.load(f)
                with open("models/cosine_tfidf_matrix_2.pkl", "rb") as f:
                    self.cosine_tfidf_matrix_2 = pickle.load(f)
                return True
            else:
                st.warning("‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y Cosine models. Vui l√≤ng train models tr∆∞·ªõc.")
                return False
        except Exception as e:
            st.error(f"‚ùå L·ªói load Cosine models: {e}")
            return False

    def find_similar_companies_gem(self, company_id, corpus, tfidf, index, top_n):
        # 1. L·∫•y vector TF-IDF c·ªßa c√¥ng ty ƒë∆∞·ª£c ch·ªçn
        tfidf_vec = tfidf[corpus[company_id]]
        # 2. T√≠nh cosine similarity gi·ªØa c√¥ng ty n√†y v√† t·∫•t c·∫£ c√°c c√¥ng ty kh√°c
        sims = index[tfidf_vec]  # (L√† t√≠nh cosin gi·ªØa vector h·ªèi v√† matran vector ƒëang c√≥, cosin g·∫ßn 1 th√¨ c√†ng // hay tr√πng nhau: [a, b] x [b, 1] = [a, 1])
        # 3. S·∫Øp x·∫øp theo ƒë·ªô t∆∞∆°ng t·ª± gi·∫£m d·∫ßn, lo·∫°i ch√≠nh n√≥ ra, l·∫•y top 5
        top_similar_gem_find = sorted([(i, sim) for i, sim in enumerate(sims) if i != company_id],key=lambda x: x[1],reverse=True)[:top_n]
        # 4. L·∫•y ID v√† similarity
        company_ids = [i[0] for i in top_similar_gem_find]
        similarities = [round(i[1], 4) for i in top_similar_gem_find]
        # 5. L·∫•y d·ªØ li·ªáu t·ª´ g·ªëc
        df_gem_find = df.iloc[company_ids].copy()
        df_gem_find['similarity'] = similarities

        return df_gem_find, top_similar_gem_find, company_id

    def search_similar_companies_gem(self, query_text, clean_pipeline, dictionary, tfidf_model, index_2, data, top_n):
        # 1. L√†m s·∫°ch v√† t√°ch t·ª´
        clean_text = self.text_processor.clean_pipeline(query_text)
        tokens = clean_text.split()  # ho·∫∑c d√πng tokenizer ri√™ng n·∫øu b·∫°n c√≥
        # 2. Chuy·ªÉn sang d·∫°ng vector BoW
        bow_vector = dictionary.doc2bow(tokens)
        # 3. Chuy·ªÉn sang vector TF-IDF
        tfidf_vector = tfidf_model[bow_vector]
        # 4. T√≠nh ƒë·ªô t∆∞∆°ng t·ª± v·ªõi to√†n b·ªô c√¥ng ty
        sims = index_2[tfidf_vector]
        # 5. S·∫Øp x·∫øp theo ƒë·ªô t∆∞∆°ng t·ª± gi·∫£m d·∫ßn
        top_similar_gem_search = sorted(enumerate(sims), key=lambda x: x[1], reverse=True)[:top_n]
        # 6. L·∫•y ID v√† similarity
        company_ids = [i[0] for i in top_similar_gem_search]
        similarities = [round(i[1], 4) for i in top_similar_gem_search]
        # 7. L·∫•y d·ªØ li·ªáu t·ª´ g·ªëc
        df_gem_search = data.iloc[company_ids].copy()
        df_gem_search['similarity'] = similarities

        return df_gem_search, top_similar_gem_search, query_text

    def find_similar_companies_cos(self, cosine_similarities, data, company_id, top_n):
        # B·ªè ch√≠nh n√≥ ra b·∫±ng c√°ch g√°n -1
        sim_scores = cosine_similarities[company_id].copy()
        sim_scores[company_id] = -1
        # L·∫•y top_n ch·ªâ s·ªë c√¥ng ty t∆∞∆°ng t·ª± nh·∫•t
        similar_indices = sim_scores.argsort()[-top_n:][::-1]
        # T·∫°o danh s√°ch (score, index)
        top_similar_cos_find = [(i, sim_scores[i]) for i in similar_indices]
        # L·∫•y d√≤ng d·ªØ li·ªáu c√¥ng ty t·ª´ DataFrame
        df_cos_find = data.iloc[similar_indices].copy()
        df_cos_find["similarity"] = [sim_scores[i] for i in similar_indices]

        return top_similar_cos_find, df_cos_find, company_id

    def search_similar_companies_cos(self,query_text_2, vectorizer, tfidf_matrix, data, top_n=5):
        # 1. L√†m s·∫°ch t·ª´ kh√≥a truy v·∫•n
        cleaned_query = ml_system.text_processor.clean_pipeline(query_text_2)
        # 2. Chuy·ªÉn th√†nh vector TF-IDF (d·∫°ng 1√ón)
        query_vector = vectorizer.transform([cleaned_query])  # gi·ªØ nguy√™n t·ª´ ƒëi·ªÉn c≈©
        # 3. T√≠nh ƒë·ªô t∆∞∆°ng ƒë·ªìng cosine v·ªõi to√†n b·ªô c√¥ng ty
        sims = cosine_similarity(query_vector, tfidf_matrix)[0]  # k·∫øt qu·∫£ l√† vector 1D
        # 4. L·∫•y top N c√¥ng ty c√≥ ƒëi·ªÉm similarity cao nh·∫•t
        similar_indices = sims.argsort()[-top_n:][::-1]  # s·∫Øp x·∫øp gi·∫£m d·∫ßn
        # 5. T·∫°o k·∫øt qu·∫£ danh s√°ch ƒëi·ªÉm v√† ch·ªâ s·ªë/
        top_similarity_cos_search = [(sims[i], i) for i in similar_indices]
        # 6. T·∫°o DataFrame c√°c c√¥ng ty t∆∞∆°ng t·ª±
        df_cos_search = data.iloc[similar_indices].copy()
        df_cos_search["similarity"] = [sims[i] for i in similar_indices]

        return top_similarity_cos_search , df_cos_search, query_text_2


   # H√†m l·∫•y index t·ª´ danh s√°ch c√¥ng ty ch·ªçn
    def suggest_company_name(self, df, key = None):
        # T·∫°o mapping: t√™n c√¥ng ty ‚Üí id (n·∫øu t√™n tr√πng nhau s·∫Ω l·∫•y ID ƒë·∫ßu ti√™n)
        company_mapping = (df.set_index("Company Name")["id"].to_dict())
        # Danh s√°ch t√™n c√¥ng ty, th√™m l·ª±a ch·ªçn ƒë·∫ßu ti√™n l√† "T·∫•t c·∫£" ho·∫∑c "-- Ch·ªçn c√¥ng ty --"
        company_list = ["-- Ch·ªçn c√¥ng ty --"] + sorted(company_mapping.keys())

        # T·∫°o selectbox
        selected_name = st.selectbox(
            "Nh·∫≠p t√™n c√¥ng ty:",
            options=company_list,
            key=key)
        
        # N·∫øu ng∆∞·ªùi d√πng ch∆∞a ch·ªçn c√¥ng ty c·ª• th·ªÉ ‚Üí tr·∫£ None
        if selected_name == "-- Ch·ªçn c√¥ng ty --":
            selected_id = None
        else:
            selected_id = company_mapping.get(selected_name, None)
        return selected_name, selected_id

    def show_company_detail(self, data, title=None, expanded=False):
        """Hi·ªÉn th·ªã chi ti·∫øt c√¥ng ty"""
        with st.expander(title or f"{data['Company Name']}", expanded=expanded):
            col1, col2 = st.columns(2)
            
            with col1:
                st.markdown(f"**üè≠ Ng√†nh:** {data.get('Company industry', 'N/A')}")
                st.markdown(f"**üë• Quy m√¥:** {data.get('Company size', 'N/A')}")
                st.markdown(f"**üåç Qu·ªëc gia:** {data.get('Country', 'N/A')}")
                st.markdown(f"**üè¢ Lo·∫°i:** {data.get('Company Type', 'N/A')}")
            
            with col2:
                st.markdown(f"**üìÖ L√†m vi·ªác:** {data.get('Working days', 'N/A')}")
                st.markdown(f"**‚è∞ Ch√≠nh s√°ch OT:** {data.get('Overtime Policy', 'N/A')}")
                st.markdown(f"**üòä ƒê·ªãa ch·ªâ:** {data.get('Location', 'N/A')}")
                st.markdown(f"**üîë Website:** {data.get('Href', 'N/A')}")
                    
            # Company details
            if 'Company overview' in data:
                st.markdown("**üìù M√¥ t·∫£ c√¥ng ty:**")
                st.write(data.get('Company overview', 'Kh√¥ng c√≥ th√¥ng tin'))
            
            if "Why you'll love working here" in data:
                st.markdown("**üíù T·∫°i sao b·∫°n s·∫Ω y√™u th√≠ch:**")
                st.write(data.get("Why you'll love working here", 'Kh√¥ng c√≥ th√¥ng tin'))
            
            if 'Our key skills' in data:
                st.markdown("**üîß K·ªπ nƒÉng c·∫ßn thi·∫øt:**")
                st.write(data.get('Our key skills', 'Kh√¥ng c√≥ th√¥ng tin'))

    def draw_similarity_bar_chart(self,df):
        df["similarity"] = df["similarity"].clip(0, 1)
        # S·∫Øp x·∫øp d·ªØ li·ªáu tƒÉng d·∫ßn theo similarity
        df_sorted = df.sort_values(by="similarity", ascending=True)

        # T·∫°o bi·ªÉu ƒë·ªì
        fig = px.bar(
            df_sorted,
            x="similarity",
            y="Company Name",
            orientation='h',
            color="similarity",
            # color_continuous_scale="Blues",
            color_continuous_scale=[
            [0.0, '#BBDEFB'],  # ƒë·∫≠m
            [0.5, '#42A5F5'],
            [1.0, '#1565C0']   # nh·∫°t
        ],
            text="similarity",
            hover_data=["Company Type", "Company industry"],  # üëâ Tooltip m·ªü r·ªông
            title="So s√°nh ƒë·ªô t∆∞∆°ng ƒë·ªìng"
        )

        fig.update_layout(
            xaxis=dict(range=[0, 1]),
            yaxis_title="T√™n c√¥ng ty",
            xaxis_title="ƒê·ªô t∆∞∆°ng ƒë·ªìng",
            height=450,
            plot_bgcolor="white"
        )
        fig.update_traces(texttemplate='%{text:.4f}', textposition='outside', textfont=dict(color='#0D47A1'))

        st.plotly_chart(fig, use_container_width=True)

import subprocess
class PySparkMLSystem:
    def __init__(self):
        self.spark = None
        self.spark_df_ml = None
        self.pyspark_results = {}

    def initialize_spark(self):
        """Kh·ªüi t·∫°o Spark Session v·ªõi ki·ªÉm tra Java"""
        try:
            # Ki·ªÉm tra java -version
            result = subprocess.run(['java', '-version'], capture_output=True, text=True)
            if result.returncode != 0:
                st.error("‚ùå Java kh√¥ng ƒë∆∞·ª£c c√†i ƒë·∫∑t ho·∫∑c kh√¥ng trong PATH")
                return False
        except FileNotFoundError:
            st.error("‚ùå Java kh√¥ng ƒë∆∞·ª£c t√¨m th·∫•y. Vui l√≤ng c√†i ƒë·∫∑t Java 8 ho·∫∑c 11.")
            return False

        try:
            # T·∫°o SparkSession an to√†n
            self.spark = SparkSession.builder \
                .appName("CompanyRecommendation") \
                .config("spark.driver.memory", "2g") \
                .config("spark.executor.memory", "2g") \
                .config("spark.sql.adaptive.enabled", "true") \
                .config("spark.sql.adaptive.coalescePartitions.enabled", "true") \
                .getOrCreate()

            # Test Spark b·∫±ng c√°ch t·∫°o DataFrame
            test_df = self.spark.createDataFrame([(1, "test")], ["id", "value"])
            test_df.count()  # √©p th·ª±c thi

            self.spark.sparkContext.setLogLevel("ERROR")
            st.success("‚úÖ Spark ƒë√£ ƒë∆∞·ª£c kh·ªüi t·∫°o th√†nh c√¥ng!")
            return True

        except Exception as e:
            st.error(f"‚ùå L·ªói kh·ªüi t·∫°o Spark: {e}")
            return False

    
    def prepare_spark_data(self, X_concat, cluster_labels):
        """Chu·∫©n b·ªã d·ªØ li·ªáu cho PySpark"""
        try:
            # Th√™m cluster labels v√†o X_concat
            X_concat_with_labels = X_concat.copy()
            X_concat_with_labels['cluster'] = cluster_labels
            
            # Convert to Spark DataFrame
            self.spark_df_ml = self.spark.createDataFrame(X_concat_with_labels)
            
            # Assemble features
            feature_columns = X_concat.columns.tolist()
            assembler = VectorAssembler(inputCols=feature_columns, outputCol="features")
            self.spark_df_ml = assembler.transform(self.spark_df_ml)
            
            # Select features and labels
            self.spark_df_ml = self.spark_df_ml.select("features", "cluster")
            
            return True
            
        except Exception as e:
            st.error(f"‚ùå L·ªói chu·∫©n b·ªã d·ªØ li·ªáu Spark: {e}")
            return False
    
    def train_pyspark_models(self):
        """Training PySpark models"""
        try:
            # Split data
            train_data, test_data = self.spark_df_ml.randomSplit([0.8, 0.2], seed=42)
            
            # Evaluator
            evaluator = MulticlassClassificationEvaluator(
                labelCol="cluster", 
                predictionCol="prediction", 
                metricName="accuracy"
            )
            
            # Logistic Regression
            lr = SparkLogisticRegression(featuresCol="features", labelCol="cluster")
            lr_model = lr.fit(train_data)
            lr_predictions = lr_model.transform(test_data)
            lr_accuracy = evaluator.evaluate(lr_predictions)
            
            # Decision Tree
            dt = SparkDecisionTreeClassifier(featuresCol="features", labelCol="cluster")
            dt_model = dt.fit(train_data)
            dt_predictions = dt_model.transform(test_data)
            dt_accuracy = evaluator.evaluate(dt_predictions)
            
            self.pyspark_results = {
                "PySpark Logistic Regression": lr_accuracy,
                "PySpark Decision Tree": dt_accuracy
            }
            
            return self.pyspark_results
            
        except Exception as e:
            st.error(f"‚ùå L·ªói training PySpark models: {e}")
            return {}
    
    def stop_spark(self):
        """D·ª´ng Spark Session"""
        if self.spark:
            self.spark.stop()

# ƒê·ªçc d·ªØ li·ªáu
df = pd.read_excel('data/Overview_Companies.xlsx')
cols_show = ["Company Name", "Company Type", "Company industry", "similarity"]

#------- I.Giao di·ªán Streamlit -----
# 1.1. H√¨nh ·∫£nh ƒë·∫ßu ti√™n
st.image('images/channels4_banner.jpg', use_container_width=True)

# 1.2.Slidebar
st.sidebar.markdown("## ü§ñ AI Company Recommendation System")
st.sidebar.markdown("---")

#Menu categories
page = st.sidebar.radio("üìã Select Category:",["Company Similarity", "Recommendation"])

# Th√¥ng tin ng∆∞·ªùi t·∫°o
st.sidebar.markdown("---")
st.sidebar.markdown("### üë• Creators Information")
st.sidebar.markdown("V√µ Minh Tr√≠")
st.sidebar.markdown("Email: trivm203@gmail.com")
st.sidebar.markdown("Ph·∫°m Th·ªã Thu Th·∫£o")
st.sidebar.markdown("Email: thaofpham@gmail.com")

# 1.3.C√°c tab n·∫±m ngang
tab1, tab2, tab3 = st.tabs(["Business Objective", "Build Project", "New Prediction"])


#------- II.N·ªôi dung ch√≠nh t·ª´ng tab -----
#2.1. T√≥m t·∫Øt d·ª± √°n (Business Objective)
with tab1:
    #2.1.1.  Company Similarity
    if page == "Company Similarity":
        st.header("COMPANY SIMILARITY")
        st.markdown("""
        ### üîç ƒê·ªÅ xu·∫•t c√¥ng ty t∆∞∆°ng t·ª± v√† ph√π h·ª£p

        D·ª± √°n **Company Similarity** ·ª©ng d·ª•ng c√°c k·ªπ thu·∫≠t **X·ª≠ l√Ω ng√¥n ng·ªØ t·ª± nhi√™n (NLP)** v√† **h·ªçc m√°y kh√¥ng gi√°m s√°t** nh·∫±m x√¢y d·ª±ng h·ªá th·ªëng ƒë·ªÅ xu·∫•t c√¥ng ty d·ª±a tr√™n n·ªôi dung m√¥ t·∫£.

        S·ª≠ d·ª•ng k·∫øt h·ª£p **Gensim (TF-IDF Vectorizer)** v√† **Cosine Similarity**, h·ªá th·ªëng gi·∫£i quy·∫øt hai b√†i to√°n ch√≠nh:

        ---

        #### üìå B√†i to√°n 1: ƒê·ªÅ xu·∫•t c√°c c√¥ng ty t∆∞∆°ng t·ª±
        Ng∆∞·ªùi d√πng ch·ªçn m·ªôt c√¥ng ty b·∫•t k·ª≥ t·ª´ danh s√°ch. H·ªá th·ªëng s·∫Ω ph√¢n t√≠ch n·ªôi dung m√¥ t·∫£ c·ªßa c√¥ng ty ƒë√≥ v√† ƒë·ªÅ xu·∫•t **5 c√¥ng ty c√≥ n·ªôi dung t∆∞∆°ng ƒë·ªìng nh·∫•t**.

        #### üìå B√†i to√°n 2: T√¨m c√¥ng ty ph√π h·ª£p v·ªõi m·ªôt m√¥ t·∫£ c·ª• th·ªÉ
        Ng∆∞·ªùi d√πng nh·∫≠p v√†o m·ªôt ƒëo·∫°n m√¥ t·∫£ mong mu·ªën (v√≠ d·ª•: m√¥i tr∆∞·ªùng l√†m vi·ªác, c√¥ng ngh·ªá s·ª≠ d·ª•ng, phong c√°ch qu·∫£n l√Ω...). H·ªá th·ªëng s·∫Ω t√≠nh to√°n ƒë·ªô t∆∞∆°ng ƒë·ªìng gi·ªØa m√¥ t·∫£ n√†y v·ªõi c√°c c√¥ng ty trong c∆° s·ªü d·ªØ li·ªáu v√† **ƒë·ªÅ xu·∫•t c√¥ng ty ph√π h·ª£p nh·∫•t**.

        ---

        #### ‚öôÔ∏è C√¥ng ngh·ªá s·ª≠ d·ª•ng:
        - **Gensim**: Vector h√≥a vƒÉn b·∫£n b·∫±ng TF-IDF  
        - **Cosine Similarity**: ƒêo ƒë·ªô t∆∞∆°ng ƒë·ªìng gi·ªØa c√°c vector m√¥ t·∫£
        """)
    #2.1.2.  Recommendation
    elif page == "Recommendation":
        st.markdown('<h1 class="main-header">üéØ Business Objective</h1>', unsafe_allow_html=True)
    
        st.markdown("""
        <div class="section-header">M·ª•c ti√™u c·ªßa d·ª± √°n</div>
    
        H·ªá th·ªëng ƒë·ªÅ xu·∫•t c√¥ng ty n√†y ƒë∆∞·ª£c ph√°t tri·ªÉn nh·∫±m:
        
        ### üéØ M·ª•c ti√™u ch√≠nh:
        - **H·ªó tr·ª£ ·ª©ng vi√™n**: Gi√∫p ·ª©ng vi√™n t√¨m ki·∫øm c√¥ng ty ph√π h·ª£p v·ªõi mong mu·ªën v√† k·ªπ nƒÉng c·ªßa h·ªç
        - **T·ªëi ∆∞u h√≥a tuy·ªÉn d·ª•ng**: C·∫£i thi·ªán qu√° tr√¨nh matching gi·ªØa ·ª©ng vi√™n v√† nh√† tuy·ªÉn d·ª•ng
        - **Ph√¢n t√≠ch th·ªã tr∆∞·ªùng**: Cung c·∫•p insights v·ªÅ xu h∆∞·ªõng tuy·ªÉn d·ª•ng v√† y√™u c·∫ßu c√¥ng vi·ªác
        
        ### üîç T√≠nh nƒÉng ch√≠nh:
        1. **Ph√¢n t√≠ch c√¥ng ty**: Cung c·∫•p th√¥ng tin chi ti·∫øt v·ªÅ c√°c c√¥ng ty h√†ng ƒë·∫ßu
        2. **ƒê·ªÅ xu·∫•t th√¥ng minh**: S·ª≠ d·ª•ng machine learning ƒë·ªÉ ƒë·ªÅ xu·∫•t c√¥ng ty ph√π h·ª£p
        3. **So s√°nh c√¥ng ty**: Gi√∫p ·ª©ng vi√™n so s√°nh c√°c l·ª±a ch·ªçn kh√°c nhau
        4. **D·ª± ƒëo√°n xu h∆∞·ªõng**: Ph√¢n t√≠ch v√† d·ª± ƒëo√°n xu h∆∞·ªõng tuy·ªÉn d·ª•ng
        
        ### üìä L·ª£i √≠ch:
        - Ti·∫øt ki·ªám th·ªùi gian t√¨m ki·∫øm vi·ªác l√†m
        - TƒÉng t·ª∑ l·ªá match th√†nh c√¥ng
        - Cung c·∫•p th√¥ng tin minh b·∫°ch v·ªÅ th·ªã tr∆∞·ªùng lao ƒë·ªông
        - H·ªó tr·ª£ quy·∫øt ƒë·ªãnh ngh·ªÅ nghi·ªáp
        
        ### ü§ñ AI Features:
        - **Vietnamese Text Processing**: X·ª≠ l√Ω vƒÉn b·∫£n ti·∫øng Vi·ªát v·ªõi teencode, stopwords
        - **TF-IDF Vectorization**: Chuy·ªÉn ƒë·ªïi vƒÉn b·∫£n th√†nh vector s·ªë
        - **K-means Clustering**: Ph√¢n nh√≥m c√¥ng ty theo ƒë·∫∑c ƒëi·ªÉm
        - **Multiple ML Models**: Random Forest, SVM, Logistic Regression, etc.
        - **Cosine Similarity**: T√≠nh to√°n ƒë·ªô t∆∞∆°ng ƒë·ªìng th√¥ng minh
        """, unsafe_allow_html=True)

#2.2. M√¥ t·∫£ thu·∫≠t to√°n (Build Project)       
with tab2:
    # Load d·ªØ li·ªáu n·∫øu ch∆∞a load
    if not st.session_state.data_loaded:
        with st.spinner("üîÑ ƒêang load d·ªØ li·ªáu..."):
            ml_system = CompanyRecommendationSystem()
            if ml_system.load_data():
                ml_system.load_gensim_models()
                ml_system.load_cosine_models()
                st.session_state.ml_system = ml_system
                st.session_state.data_loaded = True
            else:
                st.stop()

    ml_system = st.session_state.ml_system
    #2.2.1. Company Similarity
    if page == "Company Similarity":
        st.header("COMPANY SIMILARITY")
        #a) Gensim
        with st.expander("üß† Thu·∫≠t to√°n GENSIM"):
            st.markdown('#### B√†i to√°n 1:')
            st.write('D√πng c√°c n·ªôi dung ph√¢n lo·∫°i (Company Type, Company industry, Company size,...) l√†m d·ªØ li·ªáu ƒë·∫ßu v√†o')
            st.image('images/gen1_dau vao.png')
            st.write('D√πng gensim t·∫°o t·ª´ ƒëi·ªÉn dictionary v√† t·ª´ ƒëi·ªÉn t·∫ßn s·ªë t·ª´ corpus')
            st.image('images/gen1_dictionary.png')
            st.image('images/gen1_copus.png')
            st.write('Vector h√≥a b·∫±ng tf-idf ƒë·ªÉ t·∫°o ma tr·∫≠n th∆∞a th·ªõt')
            st.write('L·∫•y vector tf-idf c·ªßa 1 c√¥ng ty ƒë∆∞·ª£c ch·ªçn r·ªìi t√≠nh t·ªâ s·ªë t∆∞∆°ng t·ª± so v·ªõi ma tr·∫≠n th∆∞a')
            st.write('S·∫Øp x·∫øp v√† l·∫•y top5')
            st.image('images/gen1_top5.png')
            st.image('images/gen1_top5_df.png')
            st.markdown('#### B√†i to√°n 2:')
            st.write("D√πng c√°c n·ªôi dung m√¥ t·∫£ t·ª± do (Company overview, Our key skills, Why you'll love working here) l√†m d·ªØ li·ªáu ƒë·∫ßu v√†o")
            st.image('images/gen2_input.png')
            st.write('C√°c b∆∞·ªõc t·∫°o t·ª´ ƒëi·ªÉn v√† tf-idf t∆∞∆°ng t·ª±')
            st.write('T·ª´ kh√≥a t√¨m ki·∫øm s·∫Ω ƒë∆∞·ª£c bi·∫øn ƒë·ªïi th√†nh vector v√† so s√°nh ch·ªâ s·ªë t∆∞∆°ng t·ª±')
            st.write('s·∫Øp x·∫øp v√† l·∫•y c√¥ng ty t∆∞∆°ng ƒë·ªìng nh·∫•t')
            st.image('images/gen2_top1.png')
        #b) Cosine-similarity
        with st.expander("üìä Thu·∫≠t to√°n COSINE-SIMILARITY" ):
            st.markdown('#### B√†i to√°n 1:')
            st.write('D√πng c√°c n·ªôi dung ph√¢n lo·∫°i (Company Type, Company industry, Company size,...) l√†m d·ªØ li·ªáu ƒë·∫ßu v√†o')
            st.image('images/gen1_dau vao.png')
            st.write('Vector h√≥a tr·ª±c ti·∫øp b·∫±ng tf-idf ƒë·ªÉ t·∫°o ma tr·∫≠n th∆∞a th·ªõt')
            st.write('T√≠nh t·ªâ s·ªë t∆∞∆°ng t·ª± to√†n b·ªô ma tr·∫≠n th∆∞a')
            st.write('Tr·ª±c quan h√≥a c√°c c√¥ng ty c√≥ ch·ªâ s·ªë t∆∞∆°ng t·ª± >0.5')
            st.image('images/cos1_matran.png')
            st.write('Ch·ªçn 1 c√¥ng ty, thu·∫≠t to√°n s·∫Ω l·∫•y h√†ng ngang, s·∫Øp x·∫øp v√† l·∫•y top5')
            st.image('images/cos1_top5.png')
            st.image('images/cos1_top5_df.png')
            st.markdown('#### B√†i to√°n 2:')
            st.write("D√πng c√°c n·ªôi dung m√¥ t·∫£ t·ª± do (Company overview, Our key skills, Why you'll love working here) l√†m d·ªØ li·ªáu ƒë·∫ßu v√†o")
            st.image('images/gen2_input.png')
            st.write('C√°c b∆∞·ªõc t·∫°o tf-idf t∆∞∆°ng t·ª±')
            st.write('T·ª´ kh√≥a t√¨m ki·∫øm s·∫Ω ƒë∆∞·ª£c bi·∫øn ƒë·ªïi th√†nh vector v√† so s√°nh ch·ªâ s·ªë t∆∞∆°ng t·ª±')
            st.write('s·∫Øp x·∫øp v√† l·∫•y c√¥ng ty t∆∞∆°ng ƒë·ªìng nh·∫•t')
            st.image('images/cos2_top1.png')
    
    #2.2.2. Recommendation
    elif page == "Recommendation":
        st.header("COMPAYNY SIMILARITY")
        st.markdown('<h1 class="main-header">üî® Build Project</h1>', unsafe_allow_html=True)
    
        # Kh·ªüi t·∫°o v√† load d·ªØ li·ªáu
        if not st.session_state.data_loaded:
            with st.spinner("üîÑ ƒêang load d·ªØ li·ªáu th·ª±c..."):
                ml_system = CompanyRecommendationSystem()
                if ml_system.load_data():
                    st.session_state.ml_system = ml_system
                    st.session_state.data_loaded = True
                else:
                    st.stop()
        
        # Training options
        st.markdown("### üöÄ Training Machine Learning Models:")
        
        sklearn_training = st.button("üî¨ Train Sklearn Models", use_container_width=True)
        
        if PYSPARK_AVAILABLE:
            pyspark_training = st.button("‚ö° Train PySpark Models", use_container_width=True)
        
        else:
            st.info("üí° **PySpark kh√¥ng kh·∫£ d·ª•ng** - Ch·ªâ s·ª≠ d·ª•ng Sklearn Models")
        
        #a) Sklearn Training
        if sklearn_training and st.session_state.data_loaded:
            if not st.session_state.model_trained:
                with st.spinner("ü§ñ ƒêang training sklearn models..."):
                    ml_system = st.session_state.ml_system
                    
                    if ml_system.prepare_features():
                        results, best_model_name, best_acc, best_k = ml_system.train_models()
                        
                        if results:
                            st.session_state.model_trained = True
                            st.session_state.training_results = results
                            st.session_state.best_model_name = best_model_name
                            st.session_state.best_acc = best_acc
                            st.session_state.best_k = best_k
                            st.success("‚úÖ Sklearn Training ho√†n t·∫•t!")
                            st.rerun()
        
        #b) PySpark Training
        if PYSPARK_AVAILABLE and 'pyspark_training' in locals() and pyspark_training:
            if not st.session_state.get('pyspark_trained', False):
                if not st.session_state.model_trained:
                    st.warning("‚ö†Ô∏è Vui l√≤ng train sklearn models tr∆∞·ªõc!")
                else:
                    with st.spinner("‚ö° ƒêang training PySpark models..."):
                        try:
                            ml_system = st.session_state.ml_system
                            pyspark_system = PySparkMLSystem()
                            
                            if pyspark_system.initialize_spark():
                                # Chu·∫©n b·ªã d·ªØ li·ªáu
                                X_concat = pd.concat([
                                    ml_system.df_structured_encoded.reset_index(drop=True),
                                    pd.DataFrame(
                                        ml_system.tfidf.transform(ml_system.clustercty['combined_text']).toarray(),
                                        columns=ml_system.tfidf.get_feature_names_out()
                                    )
                                ], axis=1)
                                
                                cluster_labels = ml_system.clustercty['cluster'].values
                                
                                if pyspark_system.prepare_spark_data(X_concat, cluster_labels):
                                    pyspark_results = pyspark_system.train_pyspark_models()
                                    
                                    if pyspark_results:
                                        st.session_state.pyspark_trained = True
                                        st.session_state.pyspark_results = pyspark_results
                                        st.success("‚úÖ PySpark Training ho√†n t·∫•t!")
                                        st.rerun()
                                
                                pyspark_system.stop_spark()
                            
                        except Exception as e:
                            st.error(f"‚ùå L·ªói PySpark training: {e}")
        
        # Hi·ªÉn th·ªã k·∫øt qu·∫£
        if st.session_state.get('model_trained', False):
            st.markdown("### üìä K·∫øt qu·∫£ Training")
            
            ml_system = st.session_state.ml_system
            
            # Metrics overview
            col1, col2, col3, col4 = st.columns(4)
            with col1:
                st.metric("üìä S·ªë c√¥ng ty", len(ml_system.clustercty))
            with col2:
                st.metric("üéØ S·ªë clusters", st.session_state.best_k)
            with col3:
                st.metric("üèÜ Best Model", st.session_state.best_model_name)
            with col4:
                st.metric("üìà Best Accuracy", f"{st.session_state.best_acc:.3f}")
            
            # Sklearn Results
            st.markdown("#### üî¨ Sklearn Models Results:")
            sklearn_results_df = pd.DataFrame(st.session_state.training_results, columns=['M√¥ h√¨nh', 'Accuracy'])
            sklearn_results_df['Accuracy (%)'] = (sklearn_results_df['Accuracy'] * 100).round(2)
            sklearn_results_df['Framework'] = 'Sklearn'
            
            st.dataframe(sklearn_results_df[['M√¥ h√¨nh', 'Accuracy (%)', 'Framework']], use_container_width=True)
            
            # PySpark Results (if available)
            if st.session_state.get('pyspark_trained', False):
                st.markdown("#### ‚ö° PySpark Models Results:")
                pyspark_results = st.session_state.pyspark_results
                pyspark_results_df = pd.DataFrame(list(pyspark_results.items()), columns=['M√¥ h√¨nh', 'Accuracy'])
                pyspark_results_df['Accuracy (%)'] = (pyspark_results_df['Accuracy'] * 100).round(2)
                pyspark_results_df['Framework'] = 'PySpark'
                
                st.dataframe(pyspark_results_df[['M√¥ h√¨nh', 'Accuracy (%)', 'Framework']], use_container_width=True)
                
                # Combined comparison
                st.markdown("#### üÜö Sklearn vs PySpark Comparison:")
                combined_results = pd.concat([
                    sklearn_results_df[['M√¥ h√¨nh', 'Accuracy (%)', 'Framework']],
                    pyspark_results_df[['M√¥ h√¨nh', 'Accuracy (%)', 'Framework']]
                ], ignore_index=True)
                
                fig_comparison = px.bar(
                    combined_results, 
                    x='M√¥ h√¨nh', 
                    y='Accuracy (%)',
                    color='Framework',
                    title="Sklearn vs PySpark Models Comparison",
                    barmode='group'
                )
                fig_comparison.update_layout(xaxis_tickangle=-45)
                st.plotly_chart(fig_comparison, use_container_width=True)
            
            # Sklearn visualization
            fig_sklearn = px.bar(
                sklearn_results_df, 
                x='M√¥ h√¨nh', 
                y='Accuracy (%)',
                title="Sklearn Models Performance",
                color='Accuracy (%)',
                color_continuous_scale='viridis'
            )
            fig_sklearn.update_layout(xaxis_tickangle=-45)
            st.plotly_chart(fig_sklearn, use_container_width=True)
            
            # Cluster analysis
            st.markdown("#### üéØ Cluster Analysis:")
            if 'cluster' in ml_system.clustercty.columns:
                cluster_stats = ml_system.clustercty.groupby('cluster').agg({
                    'Company Name': 'count',
                    'Company industry': lambda x: x.mode().iloc[0] if not x.mode().empty else 'N/A',
                    'sentiment_group': lambda x: x.mode().iloc[0] if not x.mode().empty else 'N/A'
                })
                cluster_stats.columns = ['S·ªë c√¥ng ty', 'Ng√†nh ch·ªß ƒë·∫°o', 'Sentiment ch·ªß ƒë·∫°o']
                st.dataframe(cluster_stats, use_container_width=True)
                
                # Cluster distribution
                fig_cluster = px.pie(
                    values=cluster_stats['S·ªë c√¥ng ty'],
                    names=cluster_stats.index,
                    title="Ph√¢n b·ªë c√¥ng ty theo Cluster"
                )
                st.plotly_chart(fig_cluster, use_container_width=True)

#2.3. D·ª± ƒëo√°n k·∫øt qu·∫£ (New Prediction)
with tab3:
    #2.3.1.Company Similarity 
    if page == "Company Similarity":
        st.header('COMPANY SIMILARITY')
        #input      
        col1, col2, col3 = st.columns([4, 1.5, 1.5])
        with col1:
            selected_name, selected_id = ml_system.suggest_company_name(df, key="selectbox_company_1")
            query_text = st.text_input("Ho·∫∑c nh·∫≠p t·ª´ kh√≥a:")
        with col2:
            selected_model = st.selectbox("üìã Thu·∫≠t to√°n:", ["Gensim", "Cosine-similarity"], key="selectbox_algo")
        with col3:
            top_n = st.slider("üî¢ S·ªë c√¥ng ty t∆∞∆°ng t·ª±:", 1, 10, 5)

        # ‚úÖ Th√™m n√∫t t√¨m ki·∫øm
        tinh_button = st.button("üîç T√¨m ki·∫øm:", use_container_width=True)   

        # ‚úÖ Ch·ªâ ch·∫°y n·∫øu nh·∫•n n√∫t
        if tinh_button:
            if selected_model=="Gensim":
                if query_text.strip():
                    # PROCESS
                    df_gem_search, top_similar_gem_search, query_text = ml_system.search_similar_companies_gem(
                        query_text=query_text,
                        clean_pipeline=ml_system.text_processor.clean_pipeline,
                        dictionary=ml_system.gensim_dictionary_2,
                        tfidf_model=ml_system.gensim_tfidf_2,
                        index_2=ml_system.gensim_index_2,
                        data=df,
                        top_n=top_n
                    )

                    # OUTPUT
                    if df_gem_search is not None and not df_gem_search.empty:
                        search_id, search_name = top_similar_gem_search[0]

                        st.subheader("üè¢ C√¥ng ty t∆∞∆°ng ƒë·ªìng v·ªõi t·ª´ kh√≥a t√¨m ki·∫øm")
                        subtab1, subtab2 = st.tabs(["üìä Bi·ªÉu ƒë·ªì", "üìã D·ªØ li·ªáu"])
                        with subtab1:
                            ml_system.draw_similarity_bar_chart(df_gem_search)
                        with subtab2:
                            st.dataframe(df_gem_search[cols_show].style.format({"similarity": "{:.4f}"}))
                                            
                        st.subheader("üè¢ Th√¥ng tin c√¥ng ty t∆∞∆°ng t·ª±")

                        for idx, row in df_gem_search.iterrows():
                            ml_system.show_company_detail(
                                row,
                                title=f"{row['Company Name']} (Similarity: {row['similarity']:.4f})"
                            )

                elif selected_id:
                    # PROCESS
                    df_gem_find, top_similar_gem_find, selected_id = ml_system.find_similar_companies_gem(
                        company_id=selected_id,
                        corpus=ml_system.gensim_corpus,
                        tfidf=ml_system.gensim_tfidf,
                        index=ml_system.gensim_index,
                        top_n=top_n
                    )

                    # OUTPUT
                    st.subheader("üè¢ Th√¥ng tin c√¥ng ty ƒëang t√¨m ki·∫øm")
                    ml_system.show_company_detail(df[df['id'] == selected_id].iloc[0])

                    st.subheader("üèôÔ∏è C√°c c√¥ng ty t∆∞∆°ng t·ª±")
                    subtab1, subtab2 = st.tabs(["üìä Bi·ªÉu ƒë·ªì", "üìã D·ªØ li·ªáu"])
                    with subtab1:
                        ml_system.draw_similarity_bar_chart(df_gem_find)
                    with subtab2:
                        st.dataframe(df_gem_find[cols_show].style.format({"similarity": "{:.4f}"}))
                                        
                    st.subheader("üè¢ Th√¥ng tin c√¥ng ty t∆∞∆°ng t·ª±")

                    for idx, row in df_gem_find.iterrows():
                        ml_system.show_company_detail(
                            row,
                            title=f"{row['Company Name']} (Similarity: {row['similarity']:.4f})"
                        )
                else:
                    # C·∫£nh b√°o ng∆∞·ªùi d√πng ch∆∞a nh·∫≠p g√¨ c·∫£
                    st.warning("‚ö†Ô∏è Vui l√≤ng ch·ªçn c√¥ng ty ho·∫∑c nh·∫≠p t·ª´ kh√≥a.")
                
            elif selected_model=="Cosine-similarity": 
                if query_text.strip():
                    #process
                    top_similarity_cos_search , df_cos_search, query_text_2 = ml_system.search_similar_companies_cos(
                        query_text_2=query_text, 
                        vectorizer=ml_system.cosine_tfidf_2, 
                        tfidf_matrix=ml_system.cosine_tfidf_matrix_2, 
                        data=df, 
                        top_n=top_n)
                    #output
                    if df_cos_search is not None and not df_cos_search.empty:
                        search_id, search_name = top_similarity_cos_search[0]

                        st.subheader("üè¢ C√¥ng ty t∆∞∆°ng ƒë·ªìng v·ªõi t·ª´ kh√≥a t√¨m ki·∫øm")
                        subtab1, subtab2 = st.tabs(["üìä Bi·ªÉu ƒë·ªì", "üìã D·ªØ li·ªáu"])
                        with subtab1:
                            ml_system.draw_similarity_bar_chart(df_cos_search)
                        with subtab2:
                            st.dataframe(df_cos_search[cols_show].style.format({"similarity": "{:.4f}"}))
                                            
                        st.subheader("üè¢ Th√¥ng tin c√¥ng ty t∆∞∆°ng t·ª±")
                        for idx, row in df_cos_search.iterrows():
                            ml_system.show_company_detail(
                                row,
                                title=f"{row['Company Name']} (Similarity: {row['similarity']:.4f})"
                            )
                elif selected_id:
                    #process
                    top_similar_cos_find, df_cos_find, selected_id = ml_system.find_similar_companies_cos(
                        ml_system.cosine_index, 
                        df, company_id=selected_id, 
                        top_n=top_n)
                    #output
                    st.subheader("üè¢ Th√¥ng tin c√¥ng ty ƒëang t√¨m ki·∫øm")
                    ml_system.show_company_detail(df[df['id'] == selected_id].iloc[0])

                    st.subheader("üèôÔ∏è C√°c c√¥ng ty t∆∞∆°ng t·ª±")
        
                    subtab1, subtab2 = st.tabs(["üìä Bi·ªÉu ƒë·ªì", "üìã D·ªØ li·ªáu"])
                    with subtab1:
                        ml_system.draw_similarity_bar_chart(df_cos_find)
                    with subtab2:
                        st.dataframe(df_cos_find[cols_show].style.format({"similarity": "{:.4f}"}))
                                            
                    st.subheader("üè¢ Th√¥ng tin c√¥ng ty t∆∞∆°ng t·ª±")
                    for idx, row in df_cos_find.iterrows():
                        ml_system.show_company_detail(
                            row,
                            title=f"{row['Company Name']} (Similarity: {row['similarity']:.4f})"
                        ) 
                else:
                    # C·∫£nh b√°o ng∆∞·ªùi d√πng ch∆∞a nh·∫≠p g√¨ c·∫£
                    st.warning("‚ö†Ô∏è Vui l√≤ng ch·ªçn c√¥ng ty ho·∫∑c nh·∫≠p t·ª´ kh√≥a.")     

    #2.3.2. Recommendation
    elif page == "Recommendation":
        st.markdown('<h1 class="main-header">üîÆ RECOMMENDATION</h1>', unsafe_allow_html=True)
        
        if not st.session_state.get('model_trained', False):
            st.warning("‚ö†Ô∏è Vui l√≤ng train model ·ªü m·ª•c 'Build Project' tr∆∞·ªõc khi s·ª≠ d·ª•ng t√≠nh nƒÉng n√†y!")
            st.stop()
        
        ml_system = st.session_state.ml_system
        
        st.markdown("### üéØ Nh·∫≠p th√¥ng tin ƒë·ªÉ nh·∫≠n ƒë·ªÅ xu·∫•t c√¥ng ty ph√π h·ª£p")
        
        # User input form
        col1, col2 = st.columns(2)
        
        with col1:
            company_type = st.selectbox("üè¢ Lo·∫°i c√¥ng ty:", ml_system.clustercty['Company Type'].unique())
            company_industry = st.selectbox("üè≠ Ng√†nh ngh·ªÅ:", ml_system.clustercty['Company industry'].unique())
            company_size = st.selectbox("üë• Quy m√¥ c√¥ng ty:", ml_system.clustercty['Company size'].unique())
        
        with col2:
            country = st.selectbox("üåç Qu·ªëc gia:", ml_system.clustercty['Country'].unique())
            working_days = st.selectbox("üìÖ Ng√†y l√†m vi·ªác:", ml_system.clustercty['Working days'].unique())
            overtime_policy = st.selectbox("‚è∞ Ch√≠nh s√°ch OT:", ml_system.clustercty['Overtime Policy'].unique())
        
        # Text input
        text_input = st.text_area(
            "üìù M√¥ t·∫£ mong mu·ªën c·ªßa b·∫°n:",
            placeholder="V√≠ d·ª•: T√¥i mu·ªën l√†m vi·ªác trong m√¥i tr∆∞·ªùng c√¥ng ngh·ªá, s·ª≠ d·ª•ng AI v√† machine learning, c√≥ c∆° h·ªôi ph√°t tri·ªÉn...",
            height=100
        )
        
        # Similarity threshold
        threshold = st.slider("üéØ Ng∆∞·ª°ng ƒë·ªô t∆∞∆°ng ƒë·ªìng:", 0.0, 1.0, 0.1, 0.05)
        
        if st.button("üîÆ D·ª± ƒëo√°n v√† ƒê·ªÅ xu·∫•t", use_container_width=True):
            if text_input.strip():
                with st.spinner("ü§ñ AI ƒëang ph√¢n t√≠ch v√† ƒë·ªÅ xu·∫•t..."):
                    # Chu·∫©n b·ªã input
                    user_input = {
                        'Company Type': company_type,
                        'Company industry': company_industry,
                        'Company size': company_size,
                        'Country': country,
                        'Working days': working_days,
                        'Overtime Policy': overtime_policy
                    }
                    
                    # L·∫•y ƒë·ªÅ xu·∫•t
                    matched_companies, predicted_cluster = ml_system.recommend_companies(
                        user_input, text_input, threshold
                    )
                    
                    if not matched_companies.empty:
                        # Hi·ªÉn th·ªã k·∫øt qu·∫£ prediction
                        st.markdown(f"""
                        <div class="prediction-container">
                            <h3>üéØ K·∫øt qu·∫£ D·ª± ƒëo√°n</h3>
                            <p><strong>Cluster ƒë∆∞·ª£c d·ª± ƒëo√°n:</strong> {predicted_cluster}</p>
                            <p><strong>S·ªë c√¥ng ty ph√π h·ª£p:</strong> {len(matched_companies)}</p>
                            <p><strong>Ng∆∞·ª°ng t∆∞∆°ng ƒë·ªìng:</strong> {threshold}</p>
                        </div>
                        """, unsafe_allow_html=True)
                        
                        st.markdown("### üèÜ Top c√¥ng ty ƒë∆∞·ª£c ƒë·ªÅ xu·∫•t:")
                        
                        # Hi·ªÉn th·ªã t·ª´ng c√¥ng ty
                        for idx, (_, company) in enumerate(matched_companies.iterrows(), 1):
                            similarity = company['similarity_score']
                            
                            with st.expander(f"#{idx} üè¢ {company['Company Name']} - Similarity: {similarity:.3f}"):
                                col1, col2 = st.columns(2)
                                
                                with col1:
                                    st.markdown(f"**üè≠ Ng√†nh:** {company.get('Company industry', 'N/A')}")
                                    st.markdown(f"**üë• Quy m√¥:** {company.get('Company size', 'N/A')}")
                                    st.markdown(f"**üåç Qu·ªëc gia:** {company.get('Country', 'N/A')}")
                                    st.markdown(f"**üè¢ Lo·∫°i:** {company.get('Company Type', 'N/A')}")
                                
                                with col2:
                                    st.markdown(f"**üìÖ L√†m vi·ªác:** {company.get('Working days', 'N/A')}")
                                    st.markdown(f"**‚è∞ OT Policy:** {company.get('Overtime Policy', 'N/A')}")
                                    st.markdown(f"**üòä Sentiment:** {company.get('sentiment_group', 'N/A')}")
                                    st.markdown(f"**üîë Keywords:** {company.get('keyword', 'N/A')}")
                                
                                # Similarity score highlight
                                st.markdown(f"""
                                <div class="similarity-score">
                                    üéØ ƒê·ªô t∆∞∆°ng ƒë·ªìng: {similarity:.3f} ({similarity*100:.1f}%)
                                </div>
                                """, unsafe_allow_html=True)
                                
                                # Company details
                                if 'Company overview_new' in company:
                                    st.markdown("**üìù M√¥ t·∫£ c√¥ng ty:**")
                                    st.write(company.get('Company overview_new', 'Kh√¥ng c√≥ th√¥ng tin'))
                                
                                if "Why you'll love working here_new" in company:
                                    st.markdown("**üíù T·∫°i sao b·∫°n s·∫Ω y√™u th√≠ch:**")
                                    st.write(company.get("Why you'll love working here_new", 'Kh√¥ng c√≥ th√¥ng tin'))
                                
                                if 'Our key skills_new' in company:
                                    st.markdown("**üîß K·ªπ nƒÉng c·∫ßn thi·∫øt:**")
                                    st.write(company.get('Our key skills_new', 'Kh√¥ng c√≥ th√¥ng tin'))
                        
                        # Visualization
                        if len(matched_companies) > 1:
                            st.markdown("### üìä Bi·ªÉu ƒë·ªì ƒë·ªô t∆∞∆°ng ƒë·ªìng:")
                            fig_similarity = px.bar(
                                x=matched_companies['Company Name'],
                                y=matched_companies['similarity_score'],
                                title="ƒê·ªô t∆∞∆°ng ƒë·ªìng c·ªßa c√°c c√¥ng ty ƒë∆∞·ª£c ƒë·ªÅ xu·∫•t",
                                labels={'x': 'C√¥ng ty', 'y': 'ƒê·ªô t∆∞∆°ng ƒë·ªìng'}
                            )
                            fig_similarity.update_layout(xaxis_tickangle=-45)
                            st.plotly_chart(fig_similarity, use_container_width=True)
                    
                    else:
                        st.warning(f"‚ùå Kh√¥ng t√¨m th·∫•y c√¥ng ty ph√π h·ª£p v·ªõi ng∆∞·ª°ng t∆∞∆°ng ƒë·ªìng {threshold}")
                        st.info("üí° **G·ª£i √Ω:** Th·ª≠ gi·∫£m ng∆∞·ª°ng t∆∞∆°ng ƒë·ªìng ho·∫∑c thay ƒë·ªïi m√¥ t·∫£ mong mu·ªën")
            else:
                st.warning("‚ö†Ô∏è Vui l√≤ng nh·∫≠p m√¥ t·∫£ mong mu·ªën c·ªßa b·∫°n!")
    
    
# Adding a footer
footer="""<style>
a:link , a:visited{
color: blue;
background-color: transparent;
text-decoration: underline;
}

a:hover,  a:active {
color: red;
background-color: transparent;
text-decoration: underline;
}

.footer {
position: fixed;
left: 0;
bottom: 0;
width: 100%;
background-color: white;
color: black;
text-align: center;
}
.footer p {
    font-size: 17px;  /* B·∫°n c√≥ th·ªÉ ch·ªânh to h∆°n n·∫øu mu·ªën, v√≠ d·ª• 28px */
    color: blue;
    margin: 5px 0;  /* ƒê·ªÉ ch·ªØ kh√¥ng d√≠nh s√°t m√©p footer */
}

</style>
<div class="footer">
<p> Trung t√¢m Tin H·ªçc - Tr∆∞·ªùng ƒê·∫°i H·ªçc Khoa H·ªçc T·ª± Nhi√™n <br> ƒê·ªì √°n t·ªët nghi·ªáp Data Science and Machine Learning </p>
</div>
"""
st.markdown(footer,unsafe_allow_html=True)






