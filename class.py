import streamlit as st
import pandas as pd
import numpy as np
import plotly.express as px
import re
import string
import os
import json
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.decomposition import PCA
from sklearn.metrics.pairwise import cosine_similarity
import pickle
from gensim import corpora, models, similarities

# C·∫•u h√¨nh trang
st.set_page_config(
    page_title="AI Company Recommendation System AT IT_Viec",
    page_icon="ü§ñ",
    layout="wide",
    initial_sidebar_state="expanded"
)

# CSS t√πy ch·ªânh
st.markdown("""
<style>
    .main-header {
        font-size: 2.5rem;
        font-weight: bold;
        color: #1f77b4;
        text-align: center;
        margin-bottom: 2rem;
    }
    .section-header {
        font-size: 1.8rem;
        font-weight: bold;
        color: #2c3e50;
        margin-bottom: 1rem;
    }
    .company-card {
        background-color: #f8f9fa;
        padding: 1rem;
        border-radius: 10px;
        border-left: 4px solid #1f77b4;
        margin-bottom: 1rem;
    }
    .cluster-card {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        padding: 1.5rem;
        border-radius: 15px;
        color: white;
        margin-bottom: 1rem;
    }
    .sentiment-positive {
        background-color: #d4edda;
        border-left: 4px solid #28a745;
        padding: 1rem;
        border-radius: 8px;
        margin-bottom: 1rem;
    }
    .sentiment-negative {
        background-color: #f8d7da;
        border-left: 4px solid #dc3545;
        padding: 1rem;
        border-radius: 8px;
        margin-bottom: 1rem;
    }
    .sentiment-neutral {
        background-color: #fff3cd;
        border-left: 4px solid #ffc107;
        padding: 1rem;
        border-radius: 8px;
        margin-bottom: 1rem;
    }
    .prediction-container {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        padding: 2rem;
        border-radius: 15px;
        color: white;
        margin-bottom: 2rem;
    }
    .success-box {
        background-color: #d4edda;
        border: 1px solid #c3e6cb;
        color: #155724;
        padding: 1rem;
        border-radius: 5px;
        margin: 1rem 0;
    }
    .warning-box {
        background-color: #fff3cd;
        border: 1px solid #ffeaa7;
        color: #856404;
        padding: 1rem;
        border-radius: 5px;
        margin: 1rem 0;
    }
    .error-box {
        background-color: #f8d7da;
        border: 1px solid #f5c6cb;
        color: #721c24;
        padding: 1rem;
        border-radius: 5px;
        margin: 1rem 0;
    }
</style>
""", unsafe_allow_html=True)

# 1Ô∏è‚É£ Kh·ªüi t·∫°o session_state cho c√°c bi·∫øn ƒë∆°n gi·∫£n
default_state = {
    "data_loaded": False,
    "model_trained": False,
    "selectbox_company": "-- Ch·ªçn c√¥ng ty --",
    "query_text": "",
    "prev_selectbox_company": "-- Ch·ªçn c√¥ng ty --",
    "prev_query_text": ""
}
for key, value in default_state.items():
    if key not in st.session_state:
        st.session_state[key] = value

# Class x·ª≠ l√Ω vƒÉn b·∫£n t√≠ch h·ª£p t·ª´ code c·ªßa b·∫°n
class TextProcessor:
    def __init__(self):
        self.teen_dict = {}
        self.stopwords_lst = []
        self.wrong_lst = []
        self.english_dict = {}
        self.load_dictionaries()
    
    def load_dictionaries(self):
        """Load c√°c t·ª´ ƒëi·ªÉn x·ª≠ l√Ω vƒÉn b·∫£n t·ª´ files ho·∫∑c fallback"""
        try:
            # Load teencode t·ª´ file ho·∫∑c fallback
            teencode_paths = ['files/teencode.txt', 'teencode.txt']
            for path in teencode_paths:
                if os.path.exists(path):
                    with open(path, 'r', encoding="utf8") as file:
                        teen_lst = file.read().split('\n')
                        for line in teen_lst:
                            if '\t' in line:
                                key, value = line.split('\t', 1)
                                self.teen_dict[key] = str(value)
                    break
            else:
                # Fallback teencode dictionary
                self.teen_dict = {
                    'ko': 'kh√¥ng', 'k': 'kh√¥ng', 'dc': 'ƒë∆∞·ª£c', 'vs': 'v·ªõi',
                    'tks': 'thanks', 'ty': 'thank you', 'ok': 'okay', 'oke': 'okay',
                    'bt': 'b√¨nh th∆∞·ªùng', 'nc': 'n√≥i chuy·ªán', 'kb': 'k·∫øt b·∫°n'
                }
            
            # Load stopwords t·ª´ file ho·∫∑c fallback
            stopwords_paths = ['files/vietnamese-stopwords_rev.txt', 'vietnamese-stopwords_rev.txt']
            for path in stopwords_paths:
                if os.path.exists(path):
                    with open(path, 'r', encoding="utf8") as file:
                        self.stopwords_lst = file.read().split('\n')
                    break
            else:
                # Fallback stopwords
                self.stopwords_lst = [
                    'v√†', 'c·ªßa', 'c√≥', 'l√†', 'ƒë∆∞·ª£c', 'trong', 'v·ªõi', 'ƒë·ªÉ', 'cho', 't·ª´',
                    'm·ªôt', 'c√°c', 'n√†y', 'ƒë√≥', 'nh·ªØng', 'nhi·ªÅu', 'r·∫•t', 'c≈©ng', 's·∫Ω',
                    'ƒë√£', 'ƒëang', 'v·ªÅ', 'theo', 'nh∆∞', 'khi', 'n·∫øu', 'v√¨', 'do', 'b·ªüi'
                ]
            
            # Load wrong words t·ª´ file ho·∫∑c fallback
            wrong_words_paths = ['files/wrong-word_rev.txt', 'wrong-word_rev.txt']
            for path in wrong_words_paths:
                if os.path.exists(path):
                    with open(path, 'r', encoding="utf8") as file:
                        self.wrong_lst = file.read().split('\n')
                    break
            else:
                self.wrong_lst = ['zzz', 'xxx', 'aaa', 'bbb', 'ccc']

            # Load english-vnmese dictionary t·ª´ file ho·∫∑c fallback n·∫øu kh√¥ng t·ªìn t·∫°i
            english_dict_paths = ['files/english-vnmese_rev.txt', 'english-vnmese_rev.txt']
            for path in english_dict_paths:
                if os.path.exists(path):
                    with open(path, 'r', encoding='utf8') as file:
                        for line in file:
                            if '\t' in line:
                                key, value = line.strip().split('\t', 1)
                                self.english_dict[key] = value
                    break
            else:
                # Fallback t·ª´ ƒëi·ªÉn ƒë∆°n gi·∫£n n·∫øu kh√¥ng c√≥ file
                self.english_dict = {
                    "hello": "xin ch√†o",
                    "world": "th·∫ø gi·ªõi",
                    "example": "v√≠ d·ª•",
                    "test": "ki·ªÉm tra"}
                    
        except Exception as e:
            st.warning(f"‚ö†Ô∏è Kh√¥ng th·ªÉ load m·ªôt s·ªë file t·ª´ ƒëi·ªÉn: {e}")
    
    def clean_text(self, text):
        """L√†m s·∫°ch vƒÉn b·∫£n c∆° b·∫£n - t√≠ch h·ª£p t·ª´ code c·ªßa b·∫°n"""
        if not text or pd.isna(text):
            return ""
        text = str(text).lower()  # Hoa -> th∆∞·ªùng
        text = re.sub(rf"[{string.punctuation}]", "", text)  # B·ªè d·∫•u c√¢u
        text = re.sub(r"\b(g|ml)\b", "", text)  # B·ªè t·ª´ 'g' ho·∫∑c 'ml' khi n√≥ l√† c·∫£ t·ª´
        text = re.sub(r"\s+", " ", text).strip()  # X√≥a kho·∫£ng tr·∫Øng th·ª´a
        text = re.sub(r"^[\-\+\*\‚Ä¢\‚óè\¬∑\~\‚Äì\‚Äî\>]+", "", text)  # B·ªè d·∫•u ƒë·∫ßu c√¢u
        return text
    
    def translate_english(self,text):
        """D·ªãch t·ª´ ti·∫øng Anh sang ti·∫øng Vi·ªát n·∫øu ph√°t hi·ªán vƒÉn b·∫£n l√† ti·∫øng Anh"""
        def is_english(text):
            if not text:
                return False
            text = text.lower()
            eng_chars = re.findall(r"[a-z]", text)
            non_eng_chars = re.findall(r"[√†-·ªπ]", text.lower())
            return len(eng_chars) > len(non_eng_chars)

        if not is_english(text):
            return text  # N·∫øu kh√¥ng ph·∫£i ti·∫øng Anh th√¨ gi·ªØ nguy√™n
        words = text.split()
        translated = [self.english_dict.get(word, word) for word in words]
        return " ".join(translated)
    
    def fix_teencode(self, text):
        """S·ª≠a teencode - t√≠ch h·ª£p t·ª´ code c·ªßa b·∫°n"""
        words = text.split()
        corrected = [self.teen_dict.get(word, word) for word in words]
        return " ".join(corrected)
    
    def remove_wrongword(self, text):
        """Lo·∫°i b·ªè t·ª´ sai"""
        words = text.split()
        trueword = [word for word in words if word not in self.wrong_lst]
        return " ".join(trueword)
    
    def remove_stopword(self, text):
        """Lo·∫°i b·ªè stopwords - t√≠ch h·ª£p t·ª´ code c·ªßa b·∫°n"""
        words = text.split()
        stopword = [word for word in words if word not in self.stopwords_lst]
        return " ".join(stopword)
    
    def clean_pipeline(self, text):
        """Pipeline x·ª≠ l√Ω vƒÉn b·∫£n ho√†n ch·ªânh - t√≠ch h·ª£p t·ª´ code c·ªßa b·∫°n"""
        if not text or pd.isna(text):
            return ""
        text = self.clean_text(text)
        text = self.translate_english(text)
        text = self.fix_teencode(text)
        text = self.remove_wrongword(text)
        text = self.remove_stopword(text)
        return text

# Class h·ªá th·ªëng ML v·ªõi d·ªØ li·ªáu th·ª±c
class CompanyRecommendationSystem:
    def __init__(self):
        self.clustercty = None
        self.tfidf = TfidfVectorizer(max_features=500)
        self.pca = PCA(n_components=50, random_state=42)
        self.best_model = None
        self.df_structured_encoded = None
        self.X_full = None
        self.text_processor = TextProcessor()
        self.structured_cols = ['Company Type', 'Company industry', 'Company size', 'Country', 'Working days', 'Overtime Policy']
        self.text_cols = ['Company overview_new', "Why you'll love working here_new", 'Our key skills_new', 'keyword']

    def load_gensim_models(self):
        """Load pre-trained Gensim models"""
        try:
            # Gensim Problem 1
            if os.path.exists("models/gensim_dictionary.pkl"):
                with open("models/gensim_dictionary.pkl", "rb") as f:
                    self.gensim_dictionary = pickle.load(f)
                with open("models/gensim_corpus.pkl", "rb") as f:
                    self.gensim_corpus = pickle.load(f)
                self.gensim_tfidf = models.TfidfModel.load("models/gensim_tfidf_model.tfidf")
                self.gensim_index = similarities.SparseMatrixSimilarity.load("models/gensim_similarity.index")
                
                # Gensim Problem 2
                with open("models/gensim_dictionary_2.pkl", "rb") as f:
                    self.gensim_dictionary_2 = pickle.load(f)
                self.gensim_tfidf_2 = models.TfidfModel.load("models/gensim_tfidf_model_2.tfidf")
                self.gensim_index_2 = similarities.SparseMatrixSimilarity.load("models/gensim_similarity_2.index")
                
                return True
            else:
                st.warning("‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y Gensim models. Vui l√≤ng train models tr∆∞·ªõc.")
                return False
        except Exception as e:
            st.error(f"‚ùå L·ªói load Gensim models: {e}")
            return False

    def load_cosine_models(self):
        """Load pre-trained Cosine Similarity models"""
        try:
            if os.path.exists("models/cosine_index.pkl"):
                with open("models/cosine_index.pkl", "rb") as f:
                    self.cosine_index = pickle.load(f)
                with open("models/cosine_tfidf_2.pkl", "rb") as f:
                    self.cosine_tfidf_2 = pickle.load(f)
                with open("models/cosine_tfidf_matrix_2.pkl", "rb") as f:
                    self.cosine_tfidf_matrix_2 = pickle.load(f)
                return True
            else:
                st.warning("‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y Cosine models. Vui l√≤ng train models tr∆∞·ªõc.")
                return False
        except Exception as e:
            st.error(f"‚ùå L·ªói load Cosine models: {e}")
            return False

    def find_similar_companies_gem(self, company_id, corpus, tfidf, index, top_n):
        # 1. L·∫•y vector TF-IDF c·ªßa c√¥ng ty ƒë∆∞·ª£c ch·ªçn
        tfidf_vec = tfidf[corpus[company_id]]
        # 2. T√≠nh cosine similarity gi·ªØa c√¥ng ty n√†y v√† t·∫•t c·∫£ c√°c c√¥ng ty kh√°c
        sims = index[tfidf_vec]  # (L√† t√≠nh cosin gi·ªØa vector h·ªèi v√† matran vector ƒëang c√≥, cosin g·∫ßn 1 th√¨ c√†ng // hay tr√πng nhau: [a, b] x [b, 1] = [a, 1])
        # 3. S·∫Øp x·∫øp theo ƒë·ªô t∆∞∆°ng t·ª± gi·∫£m d·∫ßn, lo·∫°i ch√≠nh n√≥ ra, l·∫•y top 5
        top_similar_gem_find = sorted([(i, sim) for i, sim in enumerate(sims) if i != company_id],key=lambda x: x[1],reverse=True)[:top_n]
        # 4. L·∫•y ID v√† similarity
        company_ids = [i[0] for i in top_similar_gem_find]
        similarities = [round(i[1], 4) for i in top_similar_gem_find]
        # 5. L·∫•y d·ªØ li·ªáu t·ª´ g·ªëc
        df_gem_find = df.iloc[company_ids].copy()
        df_gem_find['similarity'] = similarities

        return df_gem_find, top_similar_gem_find, company_id

    def search_similar_companies_gem(self, query_text, clean_pipeline, dictionary, tfidf_model, index_2, data, top_n):
        # 1. L√†m s·∫°ch v√† t√°ch t·ª´
        clean_text = self.text_processor.clean_pipeline(query_text)
        tokens = clean_text.split()  # ho·∫∑c d√πng tokenizer ri√™ng n·∫øu b·∫°n c√≥
        # 2. Chuy·ªÉn sang d·∫°ng vector BoW
        bow_vector = dictionary.doc2bow(tokens)
        # 3. Chuy·ªÉn sang vector TF-IDF
        tfidf_vector = tfidf_model[bow_vector]
        # 4. T√≠nh ƒë·ªô t∆∞∆°ng t·ª± v·ªõi to√†n b·ªô c√¥ng ty
        sims = index_2[tfidf_vector]
        # 5. S·∫Øp x·∫øp theo ƒë·ªô t∆∞∆°ng t·ª± gi·∫£m d·∫ßn
        top_similar_gem_search = sorted(enumerate(sims), key=lambda x: x[1], reverse=True)[:top_n]
        # 6. L·∫•y ID v√† similarity
        company_ids = [i[0] for i in top_similar_gem_search]
        similarities = [round(i[1], 4) for i in top_similar_gem_search]
        # 7. L·∫•y d·ªØ li·ªáu t·ª´ g·ªëc
        df_gem_search = data.iloc[company_ids].copy()
        df_gem_search['similarity'] = similarities

        return df_gem_search, top_similar_gem_search, query_text

    def find_similar_companies_cos(self, cosine_similarities, data, company_id, top_n):
        # B·ªè ch√≠nh n√≥ ra b·∫±ng c√°ch g√°n -1
        sim_scores = cosine_similarities[company_id].copy()
        sim_scores[company_id] = -1
        # L·∫•y top_n ch·ªâ s·ªë c√¥ng ty t∆∞∆°ng t·ª± nh·∫•t
        similar_indices = sim_scores.argsort()[-top_n:][::-1]
        # T·∫°o danh s√°ch (score, index)
        top_similar_cos_find = [(i, sim_scores[i]) for i in similar_indices]
        # L·∫•y d√≤ng d·ªØ li·ªáu c√¥ng ty t·ª´ DataFrame
        df_cos_find = data.iloc[similar_indices].copy()
        df_cos_find["similarity"] = [sim_scores[i] for i in similar_indices]

        return top_similar_cos_find, df_cos_find, company_id

    def search_similar_companies_cos(self,query_text_2, vectorizer, tfidf_matrix, data, top_n=5):
        # 1. L√†m s·∫°ch t·ª´ kh√≥a truy v·∫•n
        cleaned_query = ml_system.text_processor.clean_pipeline(query_text_2)
        # 2. Chuy·ªÉn th√†nh vector TF-IDF (d·∫°ng 1√ón)
        query_vector = vectorizer.transform([cleaned_query])  # gi·ªØ nguy√™n t·ª´ ƒëi·ªÉn c≈©
        # 3. T√≠nh ƒë·ªô t∆∞∆°ng ƒë·ªìng cosine v·ªõi to√†n b·ªô c√¥ng ty
        sims = cosine_similarity(query_vector, tfidf_matrix)[0]  # k·∫øt qu·∫£ l√† vector 1D
        # 4. L·∫•y top N c√¥ng ty c√≥ ƒëi·ªÉm similarity cao nh·∫•t
        similar_indices = sims.argsort()[-top_n:][::-1]  # s·∫Øp x·∫øp gi·∫£m d·∫ßn
        # 5. T·∫°o k·∫øt qu·∫£ danh s√°ch ƒëi·ªÉm v√† ch·ªâ s·ªë/
        top_similarity_cos_search = [(sims[i], i) for i in similar_indices]
        # 6. T·∫°o DataFrame c√°c c√¥ng ty t∆∞∆°ng t·ª±
        df_cos_search = data.iloc[similar_indices].copy()
        df_cos_search["similarity"] = [sims[i] for i in similar_indices]

        return top_similarity_cos_search , df_cos_search, query_text_2

   # H√†m l·∫•y index t·ª´ danh s√°ch c√¥ng ty ch·ªçn
    def suggest_company_name(self, df, key = None, on_change=None):
        # T·∫°o mapping: t√™n c√¥ng ty ‚Üí id (n·∫øu t√™n tr√πng nhau s·∫Ω l·∫•y ID ƒë·∫ßu ti√™n)
        company_mapping = (df.set_index("Company Name")["id"].to_dict())
        # Danh s√°ch t√™n c√¥ng ty, th√™m l·ª±a ch·ªçn ƒë·∫ßu ti√™n l√† "T·∫•t c·∫£" ho·∫∑c "-- Ch·ªçn c√¥ng ty --"
        company_list = ["-- Ch·ªçn c√¥ng ty --"] + sorted(company_mapping.keys())

        # T·∫°o selectbox
        selected_name = st.selectbox(
            "Choose company:",
            options=company_list,
            key=key,
            on_change=on_change)
        
        # N·∫øu ng∆∞·ªùi d√πng ch∆∞a ch·ªçn c√¥ng ty c·ª• th·ªÉ ‚Üí tr·∫£ None
        if selected_name == "-- Ch·ªçn c√¥ng ty --":
            selected_id = None
        else:
            selected_id = company_mapping.get(selected_name, None)
        return selected_name, selected_id

    def show_company_detail(self, data, title=None, expanded=False):
        """Hi·ªÉn th·ªã chi ti·∫øt c√¥ng ty"""
        with st.expander(title or f"{data['Company Name']}", expanded=expanded):
            col1, col2 = st.columns(2)
            
            with col1:
                st.markdown(f"**üè≠ Ng√†nh:** {data.get('Company industry', 'N/A')}")
                st.markdown(f"**üë• Quy m√¥:** {data.get('Company size', 'N/A')}")
                st.markdown(f"**üåç Qu·ªëc gia:** {data.get('Country', 'N/A')}")
                st.markdown(f"**üè¢ Lo·∫°i:** {data.get('Company Type', 'N/A')}")
            
            with col2:
                st.markdown(f"**üìÖ L√†m vi·ªác:** {data.get('Working days', 'N/A')}")
                st.markdown(f"**‚è∞ Ch√≠nh s√°ch OT:** {data.get('Overtime Policy', 'N/A')}")
                st.markdown(f"**üòä ƒê·ªãa ch·ªâ:** {data.get('Location', 'N/A')}")
                st.markdown(f"**üîë Website:** {data.get('Href', 'N/A')}")
                    
            # Company details
            if 'Company overview' in data:
                st.markdown("**üìù M√¥ t·∫£ c√¥ng ty:**")
                st.write(data.get('Company overview', 'Kh√¥ng c√≥ th√¥ng tin'))
            
            if "Why you'll love working here" in data:
                st.markdown("**üíù T·∫°i sao b·∫°n s·∫Ω y√™u th√≠ch:**")
                st.write(data.get("Why you'll love working here", 'Kh√¥ng c√≥ th√¥ng tin'))
            
            if 'Our key skills' in data:
                st.markdown("**üîß K·ªπ nƒÉng c·∫ßn thi·∫øt:**")
                st.write(data.get('Our key skills', 'Kh√¥ng c√≥ th√¥ng tin'))

    def draw_similarity_bar_chart(self,data):
        data["similarity"] = data["similarity"].clip(0, 1)
        # S·∫Øp x·∫øp d·ªØ li·ªáu tƒÉng d·∫ßn theo similarity
        df_sorted = data.sort_values(by="similarity", ascending=True)

        # T·∫°o bi·ªÉu ƒë·ªì
        fig = px.bar(
            df_sorted,
            x="similarity",
            y="Company Name",
            orientation='h',
            color="similarity",
            # color_continuous_scale="Blues",
            color_continuous_scale=[
            [0.0, '#BBDEFB'],  # ƒë·∫≠m
            [0.5, '#42A5F5'],
            [1.0, '#1565C0']   # nh·∫°t
        ],
            text="similarity",
            hover_data=["Company Type", "Company industry"],  # üëâ Tooltip m·ªü r·ªông
            title="So s√°nh ƒë·ªô t∆∞∆°ng ƒë·ªìng"
        )

        fig.update_layout(
            xaxis=dict(range=[0, 1]),
            yaxis_title="T√™n c√¥ng ty",
            xaxis_title="ƒê·ªô t∆∞∆°ng ƒë·ªìng",
            height=450,
            plot_bgcolor="white"
        )
        fig.update_traces(texttemplate='%{text:.4f}', textposition='outside', textfont=dict(color='#0D47A1'))

        st.plotly_chart(fig, use_container_width=True)
    
    def show_similarity_results(self, data, cols_show=None):
        """Hi·ªÉn th·ªã bi·ªÉu ƒë·ªì, b·∫£ng v√† chi ti·∫øt c√¥ng ty t∆∞∆°ng ƒë·ªìng"""
        
        st.subheader("üè¢ C√¥ng ty t∆∞∆°ng ƒë·ªìng:")
        subtab1, subtab2 = st.tabs(["üìä Bi·ªÉu ƒë·ªì", "üìã D·ªØ li·ªáu"])

        with subtab1:
            self.draw_similarity_bar_chart(data)

        with subtab2:
            if cols_show is None:
                cols_show = ["Company Name", "similarity"]
            st.dataframe(data[cols_show].style.format({"similarity": "{:.4f}"}))

        st.subheader("üè¢ Th√¥ng tin c√¥ng ty t∆∞∆°ng ƒë·ªìng:")
        for idx, row in data.iterrows():
            self.show_company_detail(
                row,
                title=f"{row['Company Name']} (Similarity: {row['similarity']:.4f})"
            )

    def handle_input_conflict(self):
            # N·∫øu user ch·ªçn c√¥ng ty ‚Üí reset √¥ nh·∫≠p t·ª´ kh√≥a
            if st.session_state.selectbox_company != st.session_state.prev_selectbox_company:
                st.session_state.query_text = ""
                st.session_state.prev_selectbox_company = st.session_state.selectbox_company
                st.session_state.prev_query_text = ""

            # N·∫øu user g√µ t·ª´ kh√≥a ‚Üí reset ch·ªçn c√¥ng ty
            elif st.session_state.query_text != st.session_state.prev_query_text:
                st.session_state.selectbox_company = "-- Ch·ªçn c√¥ng ty --"
                st.session_state.prev_query_text = st.session_state.query_text
                st.session_state.prev_selectbox_company = "-- Ch·ªçn c√¥ng ty --"

# ƒê·ªçc d·ªØ li·ªáu
df = pd.read_excel('data/Overview_Companies.xlsx')
cols_show = ["Company Name", "Company Type", "Company industry", "similarity"]

# Load d·ªØ li·ªáu n·∫øu ch∆∞a load
# 2Ô∏è‚É£ Kh·ªüi t·∫°o h·ªá th·ªëng n·∫øu ch∆∞a c√≥
if not st.session_state.data_loaded:
    with st.spinner("üîÑ ƒêang load d·ªØ li·ªáu..."):
        ml_system = CompanyRecommendationSystem()
        ml_system.load_gensim_models()
        ml_system.load_cosine_models()
        st.session_state.ml_system = ml_system
        st.session_state.data_loaded = True
else:
    ml_system = st.session_state.ml_system

#------- I.Giao di·ªán Streamlit -----
# 1.1. H√¨nh ·∫£nh ƒë·∫ßu ti√™n
st.image('images/channels4_banner.jpg', use_container_width=True)

# 1.2.Slidebar
st.sidebar.markdown("## ü§ñ AI Company Recommendation System")
st.sidebar.markdown("---")

#Menu categories
page = st.sidebar.radio("üìã Select Category:",["Company Similarity", "Recommendation"])

# Th√¥ng tin ng∆∞·ªùi t·∫°o
st.sidebar.markdown("---")
st.sidebar.markdown("### üë• Creators Information")
st.sidebar.markdown("V√µ Minh Tr√≠")
st.sidebar.markdown("Email: trivm203@gmail.com")
st.sidebar.markdown("Ph·∫°m Th·ªã Thu Th·∫£o")
st.sidebar.markdown("Email: thaofpham@gmail.com")

# 1.3.C√°c tab n·∫±m ngang
tab1, tab2, tab3 = st.tabs(["Business Objective", "Build Project", "New Prediction"])

#------- II.N·ªôi dung ch√≠nh t·ª´ng tab -----
#2.1. T√≥m t·∫Øt d·ª± √°n (Business Objective)
with tab1:
    #2.1.1.  Company Similarity
    if page == "Company Similarity":
        st.markdown('<h1 class="main-header">üéØ Business Objective</h1>', unsafe_allow_html=True)
        st.markdown("""
        ### üîç ƒê·ªÅ xu·∫•t c√¥ng ty t∆∞∆°ng t·ª± v√† ph√π h·ª£p

        D·ª± √°n **Company Similarity** ·ª©ng d·ª•ng c√°c k·ªπ thu·∫≠t **X·ª≠ l√Ω ng√¥n ng·ªØ t·ª± nhi√™n (NLP)** v√† **h·ªçc m√°y kh√¥ng gi√°m s√°t** nh·∫±m x√¢y d·ª±ng h·ªá th·ªëng ƒë·ªÅ xu·∫•t c√¥ng ty d·ª±a tr√™n n·ªôi dung m√¥ t·∫£.

        S·ª≠ d·ª•ng k·∫øt h·ª£p **Gensim (TF-IDF Vectorizer)** v√† **Cosine Similarity**, h·ªá th·ªëng gi·∫£i quy·∫øt hai b√†i to√°n ch√≠nh:

        ---

        #### üìå B√†i to√°n 1: ƒê·ªÅ xu·∫•t c√°c c√¥ng ty t∆∞∆°ng t·ª±
        Ng∆∞·ªùi d√πng ch·ªçn m·ªôt c√¥ng ty b·∫•t k·ª≥ t·ª´ danh s√°ch. H·ªá th·ªëng s·∫Ω ph√¢n t√≠ch n·ªôi dung m√¥ t·∫£ c·ªßa c√¥ng ty ƒë√≥ v√† ƒë·ªÅ xu·∫•t **5 c√¥ng ty c√≥ n·ªôi dung t∆∞∆°ng ƒë·ªìng nh·∫•t**.

        #### üìå B√†i to√°n 2: T√¨m c√¥ng ty ph√π h·ª£p v·ªõi m·ªôt m√¥ t·∫£ c·ª• th·ªÉ
        Ng∆∞·ªùi d√πng nh·∫≠p v√†o m·ªôt ƒëo·∫°n m√¥ t·∫£ mong mu·ªën (v√≠ d·ª•: m√¥i tr∆∞·ªùng l√†m vi·ªác, c√¥ng ngh·ªá s·ª≠ d·ª•ng, phong c√°ch qu·∫£n l√Ω...). H·ªá th·ªëng s·∫Ω t√≠nh to√°n ƒë·ªô t∆∞∆°ng ƒë·ªìng gi·ªØa m√¥ t·∫£ n√†y v·ªõi c√°c c√¥ng ty trong c∆° s·ªü d·ªØ li·ªáu v√† **ƒë·ªÅ xu·∫•t c√¥ng ty ph√π h·ª£p nh·∫•t**.

        ---

        #### ‚öôÔ∏è C√¥ng ngh·ªá s·ª≠ d·ª•ng:
        - **Gensim**: Vector h√≥a vƒÉn b·∫£n b·∫±ng TF-IDF  
        - **Cosine Similarity**: ƒêo ƒë·ªô t∆∞∆°ng ƒë·ªìng gi·ªØa c√°c vector m√¥ t·∫£
        """)

    #2.1.2.  Recommendation
    elif page == "Recommendation":
        st.markdown('<h1 class="main-header">üéØ Business Objective</h1>', unsafe_allow_html=True)
    
        st.markdown("""
        <div class="section-header">M·ª•c ti√™u c·ªßa d·ª± √°n</div>
    
        H·ªá th·ªëng ƒë·ªÅ xu·∫•t c√¥ng ty n√†y ƒë∆∞·ª£c ph√°t tri·ªÉn nh·∫±m:
        
        ### üéØ M·ª•c ti√™u ch√≠nh:
        - **H·ªó tr·ª£ ·ª©ng vi√™n**: Gi√∫p ·ª©ng vi√™n t√¨m ki·∫øm c√¥ng ty ph√π h·ª£p v·ªõi mong mu·ªën v√† k·ªπ nƒÉng c·ªßa h·ªç
        - **T·ªëi ∆∞u h√≥a tuy·ªÉn d·ª•ng**: C·∫£i thi·ªán qu√° tr√¨nh matching gi·ªØa ·ª©ng vi√™n v√† nh√† tuy·ªÉn d·ª•ng
        - **Ph√¢n t√≠ch th·ªã tr∆∞·ªùng**: Cung c·∫•p insights v·ªÅ xu h∆∞·ªõng tuy·ªÉn d·ª•ng v√† y√™u c·∫ßu c√¥ng vi·ªác
        
        ### üîç T√≠nh nƒÉng ch√≠nh:
        1. **Ph√¢n t√≠ch c√¥ng ty**: Cung c·∫•p th√¥ng tin chi ti·∫øt v·ªÅ c√°c c√¥ng ty h√†ng ƒë·∫ßu
        2. **ƒê·ªÅ xu·∫•t th√¥ng minh**: S·ª≠ d·ª•ng machine learning ƒë·ªÉ ƒë·ªÅ xu·∫•t c√¥ng ty ph√π h·ª£p
        3. **So s√°nh c√¥ng ty**: Gi√∫p ·ª©ng vi√™n so s√°nh c√°c l·ª±a ch·ªçn kh√°c nhau
        4. **D·ª± ƒëo√°n xu h∆∞·ªõng**: Ph√¢n t√≠ch v√† d·ª± ƒëo√°n xu h∆∞·ªõng tuy·ªÉn d·ª•ng
        
        ### üìä L·ª£i √≠ch:
        - Ti·∫øt ki·ªám th·ªùi gian t√¨m ki·∫øm vi·ªác l√†m
        - TƒÉng t·ª∑ l·ªá match th√†nh c√¥ng
        - Cung c·∫•p th√¥ng tin minh b·∫°ch v·ªÅ th·ªã tr∆∞·ªùng lao ƒë·ªông
        - H·ªó tr·ª£ quy·∫øt ƒë·ªãnh ngh·ªÅ nghi·ªáp
        
        ### ü§ñ AI Features:
        - **Vietnamese Text Processing**: X·ª≠ l√Ω vƒÉn b·∫£n ti·∫øng Vi·ªát v·ªõi teencode, stopwords
        - **TF-IDF Vectorization**: Chuy·ªÉn ƒë·ªïi vƒÉn b·∫£n th√†nh vector s·ªë
        - **K-means Clustering**: Ph√¢n nh√≥m c√¥ng ty theo ƒë·∫∑c ƒëi·ªÉm
        - **Multiple ML Models**: Random Forest, SVM, Logistic Regression, etc.
        - **Cosine Similarity**: T√≠nh to√°n ƒë·ªô t∆∞∆°ng ƒë·ªìng th√¥ng minh
        """, unsafe_allow_html=True)

#2.2. M√¥ t·∫£ thu·∫≠t to√°n (Build Project)       
with tab2:
    #2.2.1. Company Similarity
    if page == "Company Similarity":
        st.markdown('<h1 class="main-header">üî® Build Project</h1>', unsafe_allow_html=True)
        #a) M√¥ t·∫£ thu·∫≠t to√°n
        st.markdown("#### ‚öôÔ∏è MODEL DESCRIPTION")
        #Gensim
        with st.expander("üß† GENSIM"):
            st.markdown("""
            #### **üìù B√†i to√°n 1: D·ª±a tr√™n d·ªØ li·ªáu ph√¢n lo·∫°i**
    - S·ª≠ d·ª•ng: `Company Type`, `Company industry`, `Company size`, `Country`, `Working days`, `Overtime Policy`
    - T·∫°o **dictionary**, **corpus**.
    - Vector h√≥a b·∫±ng **TF-IDF**.
    - T√≠nh ƒë·ªô t∆∞∆°ng t·ª± v√† ch·ªçn **Top 5 c√¥ng ty gi·ªëng nh·∫•t**.
    """)
            st.markdown("""
            #### **üìù B√†i to√°n 2: D·ª±a tr√™n m√¥ t·∫£ t·ª± do**
    - D√πng c√°c tr∆∞·ªùng: `Company Overview`, `Key Skills`, `Why you'll love working here`.
    - T·∫°o TF-IDF v√† vector h√≥a t·ª´ **truy v·∫•n ng∆∞·ªùi d√πng**.
    - So s√°nh v√† ch·ªçn **c√¥ng ty ph√π h·ª£p nh·∫•t**.
    """)
        #Cosine-similarity
        with st.expander("üìä COSINE-SIMILARITY" ):
            st.markdown("""
            #### **üìù B√†i to√°n 1: D·ª±a tr√™n d·ªØ li·ªáu ph√¢n lo·∫°i**
    - S·ª≠ d·ª•ng: `Company Type`, `Company industry`, `Company size`, `Country`, `Working days`, `Overtime Policy`
    - Vector h√≥a c√°c tr∆∞·ªùng ph√¢n lo·∫°i b·∫±ng **TF-IDF**.
    - T√≠nh to√°n **cosine similarity** gi·ªØa c√°c vector c√¥ng ty.
    - L·ªçc c√°c c·∫∑p c√¥ng ty c√≥ ƒë·ªô t∆∞∆°ng t·ª± **l·ªõn h∆°n 0.5** ƒë·ªÉ tr·ª±c quan h√≥a.
    - Khi ng∆∞·ªùi d√πng ch·ªçn 1 c√¥ng ty:
        + L·∫•y **h√†ng t∆∞∆°ng ·ª©ng trong ma tr·∫≠n ƒë·ªô t∆∞∆°ng t·ª±**.
        + **S·∫Øp x·∫øp** theo ƒë·ªô t∆∞∆°ng ƒë·ªìng gi·∫£m d·∫ßn.
        + Tr·∫£ v·ªÅ **Top 5 c√¥ng ty t∆∞∆°ng ƒë·ªìng nh·∫•t**.
    """)
            st.markdown("""
            #### **üìù B√†i to√°n 2: D·ª±a tr√™n m√¥ t·∫£ t·ª± do**
    - D√πng c√°c tr∆∞·ªùng: `Company Overview`, `Key Skills`, `Why you'll love working here`.
    - T·∫°o **TF-IDF vector** t·ª´ c√°c m√¥ t·∫£ t·ª± do c·ªßa t·ª´ng c√¥ng ty.
    - Bi·∫øn ƒë·ªïi **truy v·∫•n ho·∫∑c t·ª´ kh√≥a ng∆∞·ªùi d√πng nh·∫≠p** th√†nh vector TF-IDF.
    - T√≠nh to√°n **cosine similarity** gi·ªØa truy v·∫•n v√† t·∫•t c·∫£ c√¥ng ty.
    - Tr·∫£ v·ªÅ **c√¥ng ty c√≥ ƒë·ªô t∆∞∆°ng ƒë·ªìng cao nh·∫•t** v·ªõi truy v·∫•n.
    """) 
        #b) EDA d·ªØ li·ªáu    
        st.markdown("#### üß≠ Input Data EDA")
        
        tab4, tab5 = st.tabs(["üìä Categories Analysis", "üìù Free Text Analysis"])

        with tab4:
            st.image("images/eda_input_text_cot.png", caption="üìä T·ªïng quan 6 tr∆∞·ªùng ph√¢n lo·∫°i\n(Company Type, Industry, Size, Country, ...)")
            st.markdown("")
            st.image("images/eda_company_type_piechart.png", caption="ü•ß Ph√¢n ph·ªëi c√°c c√¥ng ty d·ª±a tr√™n lo·∫°i h√¨nh ho·∫°t ƒë·ªông")

        with tab5:
            st.image("images/eda_noidungcty_word_cloud.png", caption="‚òÅÔ∏è WordCloud: T·ªïng h·ª£p m√¥ t·∫£ c√¥ng ty\n(Overview, Skills, Why you'll love)")
            st.markdown("")
            st.image("images/eda_kill_word_cloud.png", caption="üéØ K·ªπ nƒÉng y√™u c·∫ßu t·∫°i c√°c c√¥ng ty")
                                
    #2.2.2. Recommendation
    elif page == "Recommendation":
        st.markdown('<h1 class="main-header">üî® Build Project</h1>', unsafe_allow_html=True)

        try:
            with open("data/training_meta.json", "r", encoding="utf-8") as f:
                training_meta = json.load(f)
            sklearn_df = pd.read_csv("data/sklearn_results.csv")
            with open("data/pyspark_results.json", "r", encoding="utf-8") as f:
                pyspark_results = json.load(f)
            with open("models/cluster_data.pkl", "rb") as f:
                clustercty = pickle.load(f)

            st.success("‚úÖ ƒê√£ load k·∫øt qu·∫£ t·ª´ m√¥ h√¨nh ƒë√£ train!")

            # Hi·ªÉn th·ªã metric t·ªïng quan
            col1, col2, col3, col4 = st.columns(4)
            with col1:
                st.metric("üìä T·ªïng c√¥ng ty", len(clustercty))
            with col2:
                st.metric("üéØ S·ªë cluster", clustercty['cluster'].nunique())
            with col3:
                st.metric("üèÜ Best model", training_meta["best_model"])
            with col4:
                st.metric("üìà Accuracy", f"{training_meta['best_accuracy'] * 100:.2f}%")

            # Hi·ªÉn th·ªã b·∫£ng v√† bi·ªÉu ƒë·ªì
            st.markdown("### üìä So s√°nh c√°c m√¥ h√¨nh")
            st.image("images/comparison_all_models.png", caption="So s√°nh m√¥ h√¨nh Sklearn & PySpark", use_container_width=True)

            st.markdown("### üç∞ Ph√¢n b·ªë c√¥ng ty theo Cluster")
            st.image("images/cluster_distribution_pie.png", caption="T·ª∑ l·ªá c√°c c·ª•m c√¥ng ty", use_container_width=True)

            st.markdown("### üîç K·∫øt qu·∫£ chi ti·∫øt:")
            st.subheader("üî¨ Sklearn Models")
            sklearn_df = pd.read_csv("data/sklearn_results.csv", index_col=0)
            sklearn_df.reset_index(inplace=True)
            sklearn_df.rename(columns={"index": "Model"}, inplace=True)
            sklearn_df["Accuracy (%)"] = sklearn_df["Sklearn Accuracy"] * 100
            st.dataframe(sklearn_df[["Model", "Sklearn Accuracy", "Accuracy (%)"]], use_container_width=True)



            st.subheader("‚ö° PySpark Models")
            pyspark_df = pd.DataFrame.from_dict(pyspark_results, orient="index", columns=["Accuracy"])
            pyspark_df["Accuracy (%)"] = pyspark_df["Accuracy"] * 100
            st.dataframe(pyspark_df[["Accuracy (%)"]], use_container_width=True)

        except Exception as e:
            st.error(f"‚ùå Kh√¥ng th·ªÉ load k·∫øt qu·∫£: {e}")
            st.info("üìå Vui l√≤ng ch·∫°y file `train_and_save_model.py` tr∆∞·ªõc.")

#2.3. D·ª± ƒëo√°n k·∫øt qu·∫£ (New Prediction)
with tab3:
    #2.3.1.Company Similarity 
    if page == "Company Similarity":

        st.markdown('<h1 class="main-header">üîÆ COMPANY SIMILARITY</h1>', unsafe_allow_html=True)
        #input
        ml_system.handle_input_conflict()  

        col1, col2, col3 = st.columns([4, 1.5, 1.5])
        with col1:               
            # ƒê·∫∑t m·∫∑c ƒë·ªãnh n·∫øu ch∆∞a c√≥ key trong session_state
            selected_name, selected_id = ml_system.suggest_company_name(df, key="selectbox_company")

            query_text = st.text_area("Or type a keyword: ", 
                                    placeholder="VD: CNTT chuy√™n v·ªÅ m·∫£ng Blockchain, AI. C√¥ng ty l√†m vi·ªác v·ªõi kh√°ch h√†ng Nh·∫≠t B·∫£n...",
                                    height=70,
                                    key="query_text")
      
        with col2:
            selected_model = st.selectbox("üìã Model:", ["Gensim", "Cosine-similarity"], key="selectbox_algo")
        with col3:
            top_n = st.slider("üî¢ Number of results:", 1, 10, 5)

        # ‚úÖ Th√™m n√∫t t√¨m ki·∫øm
        tinh_button = st.button("üîç Search:", use_container_width=True)   

        # ‚úÖ Ch·ªâ ch·∫°y n·∫øu nh·∫•n n√∫t
        if tinh_button:
            if st.session_state.selectbox_algo=="Gensim":
                if st.session_state.query_text.strip():
                    # PROCESS
                    df_gem_search, top_similar_gem_search, query_text = ml_system.search_similar_companies_gem(
                        query_text=query_text,
                        clean_pipeline=ml_system.text_processor.clean_pipeline,
                        dictionary=ml_system.gensim_dictionary_2,
                        tfidf_model=ml_system.gensim_tfidf_2,
                        index_2=ml_system.gensim_index_2,
                        data=df,
                        top_n=top_n
                    )

                    # OUTPUT
                    if df_gem_search is not None and not df_gem_search.empty:
                        search_id, search_name = top_similar_gem_search[0]

                        ml_system.show_similarity_results(df_gem_search, cols_show=cols_show)

                elif st.session_state.selectbox_company != "-- Ch·ªçn c√¥ng ty --":
                    # PROCESS
                    df_gem_find, top_similar_gem_find, selected_id = ml_system.find_similar_companies_gem(
                        company_id=selected_id,
                        corpus=ml_system.gensim_corpus,
                        tfidf=ml_system.gensim_tfidf,
                        index=ml_system.gensim_index,
                        top_n=top_n
                    )

                    # OUTPUT
                    st.subheader("üè¢ Th√¥ng tin c√¥ng ty ƒëang t√¨m ki·∫øm")
                    ml_system.show_company_detail(df[df['id'] == selected_id].iloc[0])

                    ml_system.show_similarity_results(df_gem_find, cols_show=cols_show)
                else:
                    # C·∫£nh b√°o ng∆∞·ªùi d√πng ch∆∞a nh·∫≠p g√¨ c·∫£
                    st.warning("‚ö†Ô∏è Vui l√≤ng ch·ªçn c√¥ng ty ho·∫∑c nh·∫≠p t·ª´ kh√≥a.")
                
            elif st.session_state.selectbox_algo=="Cosine-similarity": 
                if st.session_state.query_text.strip():
                    #process
                    top_similarity_cos_search , df_cos_search, query_text_2 = ml_system.search_similar_companies_cos(
                        query_text_2=query_text, 
                        vectorizer=ml_system.cosine_tfidf_2, 
                        tfidf_matrix=ml_system.cosine_tfidf_matrix_2, 
                        data=df, 
                        top_n=top_n)
                    #output
                    if df_cos_search is not None and not df_cos_search.empty:
                        search_id, search_name = top_similarity_cos_search[0]

                        ml_system.show_similarity_results(df_cos_search, cols_show=cols_show)
                
                elif st.session_state.selectbox_company != "-- Ch·ªçn c√¥ng ty --":
                    #process
                    top_similar_cos_find, df_cos_find, selected_id = ml_system.find_similar_companies_cos(
                        ml_system.cosine_index, 
                        df, company_id=selected_id, 
                        top_n=top_n)
                    #output
                    st.subheader("üè¢ Th√¥ng tin c√¥ng ty ƒëang t√¨m ki·∫øm")
                    ml_system.show_company_detail(df[df['id'] == selected_id].iloc[0])

                    ml_system.show_similarity_results(df_cos_find, cols_show=cols_show)
                
                else:
                    # C·∫£nh b√°o ng∆∞·ªùi d√πng ch∆∞a nh·∫≠p g√¨ c·∫£
                    st.warning("‚ö†Ô∏è Vui l√≤ng ch·ªçn c√¥ng ty ho·∫∑c nh·∫≠p t·ª´ kh√≥a.")     

    #2.3.2. Recommendation
    elif page == "Recommendation":
        st.markdown('<h1 class="main-header">üîÆ RECOMMENDATION</h1>', unsafe_allow_html=True)
        try:
            # Load c√°c th√†nh ph·∫ßn ƒë√£ hu·∫•n luy·ªán
            with open("models/best_model.pkl", "rb") as f:
                best_model = pickle.load(f)
            with open("models/tfidf.pkl", "rb") as f:
                tfidf = pickle.load(f)
            with open("models/pca.pkl", "rb") as f:
                pca = pickle.load(f)
            with open("models/encoded_columns.pkl", "rb") as f:
                encoded_columns = pickle.load(f)
            with open("models/cluster_data.pkl", "rb") as f:
                clustercty = pickle.load(f)

            processor = TextProcessor()
            st.success("‚úÖ M√¥ h√¨nh v√† d·ªØ li·ªáu ƒë√£ ƒë∆∞·ª£c t·∫£i th√†nh c√¥ng!")

            # Nh·∫≠p input t·ª´ ng∆∞·ªùi d√πng
            col1, col2 = st.columns(2)
            with col1:
                company_type = st.selectbox("üè¢ Lo·∫°i c√¥ng ty", clustercty['Company Type'].unique())
                company_industry = st.selectbox("üè≠ Ng√†nh ngh·ªÅ", clustercty['Company industry'].unique())
                company_size = st.selectbox("üë• Quy m√¥", clustercty['Company size'].unique())
            with col2:
                country = st.selectbox("üåç Qu·ªëc gia", clustercty['Country'].unique())
                working_days = st.selectbox("üìÖ Ng√†y l√†m vi·ªác", clustercty['Working days'].unique())
                ot_policy = st.selectbox("‚è∞ Ch√≠nh s√°ch OT", clustercty['Overtime Policy'].unique())

            text_input = st.text_area("üìù M√¥ t·∫£ mong mu·ªën c·ªßa b·∫°n:",
            placeholder="V√≠ d·ª•: T√¥i mu·ªën l√†m vi·ªác trong m√¥i tr∆∞·ªùng c√¥ng ngh·ªá, s·ª≠ d·ª•ng AI v√† machine learning, c√≥ c∆° h·ªôi ph√°t tri·ªÉn...",
            height=100)
            threshold = st.slider("üéØ Ng∆∞·ª°ng ƒë·ªô t∆∞∆°ng ƒë·ªìng:", 0.0, 1.0, 0.1, 0.05)

            if st.button("üîç ƒê·ªÅ xu·∫•t c√¥ng ty", use_container_width=True):
                if not text_input.strip():
                    st.warning("‚ö†Ô∏è Vui l√≤ng nh·∫≠p m√¥ t·∫£ mong mu·ªën c·ªßa b·∫°n.")
                    st.stop()

                with st.spinner("ü§ñ AI ƒëang ph√¢n t√≠ch..."):
                    cleaned_text = processor.clean_pipeline(text_input)
                    text_vec = tfidf.transform([cleaned_text])

                    input_df = pd.DataFrame([{
                        "Company Type": company_type,
                        "Company industry": company_industry,
                        "Company size": company_size,
                        "Country": country,
                        "Working days": working_days,
                        "Overtime Policy": ot_policy
                    }])
                    input_encoded = pd.get_dummies(input_df)
                    for col in encoded_columns:
                        if col not in input_encoded.columns:
                            input_encoded[col] = 0
                    input_encoded = input_encoded[encoded_columns]

                    X_full = pd.concat([
                        input_encoded.reset_index(drop=True),
                        pd.DataFrame(text_vec.toarray(), columns=tfidf.get_feature_names_out())
                    ], axis=1)
                    X_pca = pca.transform(X_full)
                    pred_cluster = best_model.predict(X_pca)[0]

                    from sklearn.metrics.pairwise import cosine_similarity
                    all_vecs = tfidf.transform(clustercty["combined_text"])
                    sim_scores = cosine_similarity(text_vec, all_vecs).flatten()

                    clustercty["similarity_score"] = sim_scores
                    matched = clustercty[(clustercty["cluster"] == pred_cluster) & (clustercty["similarity_score"] >= threshold)]
                    matched = matched.sort_values(by="similarity_score", ascending=False).head(10)

                    if not matched.empty:
                        st.markdown(f"""
                        <div class="prediction-container">
                            <h3>üéØ K·∫øt qu·∫£ D·ª± ƒëo√°n</h3>
                            <p><strong>Cluster ƒë∆∞·ª£c d·ª± ƒëo√°n:</strong> {pred_cluster}</p>
                            <p><strong>S·ªë c√¥ng ty ph√π h·ª£p:</strong> {len(matched)}</p>
                            <p><strong>Ng∆∞·ª°ng t∆∞∆°ng ƒë·ªìng:</strong> {threshold}</p>
                        </div>
                        """, unsafe_allow_html=True)

                        st.markdown("### üèÜ C√°c c√¥ng ty ƒë∆∞·ª£c ƒë·ªÅ xu·∫•t:")

                        # üí° D√πng l·∫°i show_company_detail()
                        ml_system = CompanyRecommendationSystem()
                        ml_system.clustercty = clustercty  # truy·ªÅn data v√†o class ƒë·ªÉ hi·ªÉn th·ªã n·ªôi dung

                        for idx, row in matched.iterrows():
                            ml_system.show_company_detail(
                                row,
                                title=f"#{idx+1} {row['Company Name']} - Similarity: {row['similarity_score']:.3f}",
                                expanded=False
                            )

                        if len(matched) > 1:
                            st.markdown("### üìä Bi·ªÉu ƒë·ªì ƒë·ªô t∆∞∆°ng ƒë·ªìng:")
                            fig = px.bar(
                                matched,
                                x="Company Name",
                                y="similarity_score",
                                title="üéØ ƒê·ªô t∆∞∆°ng ƒë·ªìng c√°c c√¥ng ty ƒë∆∞·ª£c ƒë·ªÅ xu·∫•t",
                                labels={'x': 'C√¥ng ty', 'y': 'ƒê·ªô t∆∞∆°ng ƒë·ªìng'}
                            )
                            fig.update_layout(xaxis_tickangle=-45)
                            st.plotly_chart(fig, use_container_width=True)
                    else:
                        st.warning("‚ùå Kh√¥ng t√¨m th·∫•y c√¥ng ty ph√π h·ª£p v·ªõi ti√™u ch√≠ ƒë√£ ch·ªçn.")

        except Exception as e:
            st.error(f"‚ùå L·ªói khi t·∫£i m√¥ h√¨nh ho·∫∑c d·ªØ li·ªáu: {e}")
    
    
# Adding a footer
footer="""<style>
a:link , a:visited{
color: blue;
background-color: transparent;
text-decoration: underline;
}

a:hover,  a:active {
color: red;
background-color: transparent;
text-decoration: underline;
}

.footer {
position: fixed;
left: 0;
bottom: 0;
width: 100%;
background-color: white;
color: black;
text-align: center;
}
.footer p {
    font-size: 17px;  /* B·∫°n c√≥ th·ªÉ ch·ªânh to h∆°n n·∫øu mu·ªën, v√≠ d·ª• 28px */
    color: blue;
    margin: 5px 0;  /* ƒê·ªÉ ch·ªØ kh√¥ng d√≠nh s√°t m√©p footer */
}

</style>
<div class="footer">
<p> Trung t√¢m Tin H·ªçc - Tr∆∞·ªùng ƒê·∫°i H·ªçc Khoa H·ªçc T·ª± Nhi√™n <br> ƒê·ªì √°n t·ªët nghi·ªáp Data Science and Machine Learning </p>
</div>
"""
st.markdown(footer,unsafe_allow_html=True)